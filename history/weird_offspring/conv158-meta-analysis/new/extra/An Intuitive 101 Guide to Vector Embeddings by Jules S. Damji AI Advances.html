<!doctype html><html lang="en"><head><title data-rh="true">An Intuitive 101 Guide to Vector Embeddings | by Jules S. Damji | AI Advances</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2024-06-12T17:54:11.541Z"/><meta data-rh="true" name="title" content="An Intuitive 101 Guide to Vector Embeddings | by Jules S. Damji | AI Advances"/><meta data-rh="true" property="og:title" content="An Intuitive 101 Guide to Vector Embeddings"/><meta data-rh="true" property="al:android:url" content="medium://p/ffde295c3558"/><meta data-rh="true" property="al:ios:url" content="medium://p/ffde295c3558"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="Embeddings, particularly text or word embeddings, are not novel today. Bengio et al. originally coined the term ‘word embeddings’ in 2003, training them in a Neural Probabilistic Language Model along…"/><meta data-rh="true" property="og:description" content="Vector embeddings matter as fundamental building blocks for Generative AI"/><meta data-rh="true" property="og:url" content="https://ai.gopubby.com/an-intuitive-101-guide-to-vector-embeddings-ffde295c3558"/><meta data-rh="true" property="al:web:url" content="https://ai.gopubby.com/an-intuitive-101-guide-to-vector-embeddings-ffde295c3558"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/da:true/resize:fit:1200/0*VGQaay1U0-9NfA2D"/><meta data-rh="true" property="article:author" content="https://medium.com/@2twitme"/><meta data-rh="true" name="author" content="Jules S. Damji"/><meta data-rh="true" name="robots" content="index,noarchive,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="An Intuitive 101 Guide to Vector Embeddings"/><meta data-rh="true" name="twitter:site" content="@AIAdvances"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/ffde295c3558"/><meta data-rh="true" property="twitter:description" content="Vector embeddings matter as fundamental building blocks for Generative AI"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/da:true/resize:fit:1200/0*VGQaay1U0-9NfA2D"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:creator" content="@2twitme"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="9 min read"/><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/resize:fill:256:256/1*8xkFb5PlJ9-jlzImmpZsGg.png"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:304:304/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:240:240/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:152:152/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:120:120/10fd5c419ac61637245384e7099e131627900034828f4f386bdaa47a74eae156"/><link data-rh="true" rel="mask-icon" href="https://miro.medium.com/v2/resize:fill:1000:1000/7*GAOKVe--MXbEJmV9230oOQ.png" color="#171717"/><link data-rh="true" rel="preconnect" href="https://glyph.medium.com" crossOrigin=""/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://medium.com/@2twitme"/><link data-rh="true" rel="canonical" href="https://ai.gopubby.com/an-intuitive-101-guide-to-vector-embeddings-ffde295c3558"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/ffde295c3558"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fda:true\u002Fresize:fit:1200\u002F0*VGQaay1U0-9NfA2D"],"url":"https:\u002F\u002Fai.gopubby.com\u002Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558","dateCreated":"2024-03-22T19:41:51.132Z","datePublished":"2024-03-22T19:41:51.132Z","dateModified":"2024-06-16T09:11:04.437Z","headline":"An Intuitive 101 Guide to Vector Embeddings - AI Advances","name":"An Intuitive 101 Guide to Vector Embeddings - AI Advances","description":"Embeddings, particularly text or word embeddings, are not novel today. Bengio et al. originally coined the term ‘word embeddings’ in 2003, training them in a Neural Probabilistic Language Model along…","identifier":"ffde295c3558","author":{"@type":"Person","name":"Jules S. Damji","url":"https:\u002F\u002Fai.gopubby.com\u002F@2twitme"},"creator":["Jules S. Damji"],"publisher":{"@type":"Organization","name":"AI Advances","url":"ai.gopubby.com","logo":{"@type":"ImageObject","width":272,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:544\u002F7*V1_7XP4snlmqrc_0Njontw.png"}},"mainEntityOfPage":"https:\u002F\u002Fai.gopubby.com\u002Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558"}</script><style type="text/css" data-fela-rehydration="538" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}.grecaptcha-badge{visibility:hidden}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="538" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{width:auto}.av path{fill:#242424}.aw{height:25px}.ax{margin-left:16px}.ay{border:none}.az{border-radius:20px}.ba{width:240px}.bb{background:#F9F9F9}.bc path{fill:#6B6B6B}.be{outline:none}.bf{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bg{font-size:14px}.bh{width:100%}.bi{padding:10px 20px 10px 0}.bj{background-color:transparent}.bk{color:#242424}.bl::placeholder{color:#6B6B6B}.bm{display:inline-block}.bn{margin-left:12px}.bo{margin-right:12px}.bp{border-radius:4px}.bq{margin-left:24px}.br{height:24px}.bx{background-color:#F9F9F9}.by{border-radius:50%}.bz{height:32px}.ca{width:32px}.cb{justify-content:center}.ch{max-width:680px}.ci{min-width:0}.cj{animation:k1 1.2s ease-in-out infinite}.ck{height:100vh}.cl{margin-bottom:16px}.cm{margin-top:48px}.cn{align-items:flex-start}.co{flex-direction:column}.cp{justify-content:space-between}.cq{margin-bottom:24px}.cw{width:80%}.cx{background-color:#F2F2F2}.dd{height:44px}.de{width:44px}.df{margin:auto 0}.dg{margin-bottom:4px}.dh{height:16px}.di{width:120px}.dj{width:80px}.dp{margin-bottom:8px}.dq{width:96%}.dr{width:98%}.ds{width:81%}.dt{margin-left:8px}.du{color:#6B6B6B}.dv{font-size:13px}.dw{height:100%}.ep{color:#FFFFFF}.eq{fill:#FFFFFF}.er{background:rgba(98, 136, 193, 1)}.es{border-color:rgba(98, 136, 193, 1)}.ew:disabled{cursor:inherit !important}.ex:disabled{opacity:0.3}.ey:disabled:hover{background:rgba(98, 136, 193, 1)}.ez:disabled:hover{border-color:rgba(98, 136, 193, 1)}.fa{border-radius:99em}.fb{border-width:1px}.fc{border-style:solid}.fd{box-sizing:border-box}.fe{text-decoration:none}.ff{text-align:center}.fi{margin-right:32px}.fj{position:relative}.fk{fill:#6B6B6B}.fn{background:transparent}.fo svg{margin-left:4px}.fp svg{fill:#6B6B6B}.fr{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fs{position:absolute}.fz{margin:0 24px}.gd{background:rgba(255, 255, 255, 1)}.ge{border:1px solid #F2F2F2}.gf{box-shadow:0 1px 4px #F2F2F2}.gg{max-height:100vh}.gh{overflow-y:auto}.gi{left:0}.gj{top:calc(100vh + 100px)}.gk{bottom:calc(100vh + 100px)}.gl{width:10px}.gm{pointer-events:none}.gn{word-break:break-word}.go{word-wrap:break-word}.gp:after{display:block}.gq:after{content:""}.gr:after{clear:both}.gs{line-height:1.23}.gt{letter-spacing:0}.gu{font-style:normal}.gv{font-weight:700}.hq{margin-bottom:-0.27em}.hr{line-height:1.394}.im{align-items:baseline}.in{width:48px}.io{height:48px}.ip{border:2px solid rgba(255, 255, 255, 1)}.iq{z-index:0}.ir{box-shadow:none}.is{border:1px solid rgba(0, 0, 0, 0.05)}.it{margin-left:-12px}.iu{width:28px}.iv{height:28px}.iw{z-index:1}.ix{width:24px}.iy{margin-bottom:2px}.iz{flex-wrap:nowrap}.ja{font-size:16px}.jb{line-height:24px}.jd{margin:0 8px}.je{display:inline}.jf{color:rgba(98, 136, 193, 1)}.jg{fill:rgba(98, 136, 193, 1)}.jj{flex:0 0 auto}.jm{flex-wrap:wrap}.jp{white-space:pre-wrap}.jq{margin-right:4px}.jr{overflow:hidden}.js{max-height:20px}.jt{text-overflow:ellipsis}.ju{display:-webkit-box}.jv{-webkit-line-clamp:1}.jw{-webkit-box-orient:vertical}.jx{word-break:break-all}.jz{padding-left:8px}.ka{padding-right:8px}.lb> *{flex-shrink:0}.lc{overflow-x:scroll}.ld::-webkit-scrollbar{display:none}.le{scrollbar-width:none}.lf{-ms-overflow-style:none}.lg{width:74px}.lh{flex-direction:row}.li{z-index:2}.ll{-webkit-user-select:none}.lm{border:0}.ln{fill:rgba(117, 117, 117, 1)}.lq{outline:0}.lr{user-select:none}.ls> svg{pointer-events:none}.mb{cursor:progress}.mc{opacity:1}.md{padding:4px 0}.mg{margin-top:0px}.mh{width:16px}.mj{display:inline-flex}.mp{max-width:100%}.mq{padding:8px 2px}.mr svg{color:#6B6B6B}.ni{line-height:1.12}.nj{letter-spacing:-0.022em}.nk{font-weight:600}.od{margin-bottom:-0.28em}.oe{line-height:1.58}.of{letter-spacing:-0.004em}.og{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.oz{margin-bottom:-0.46em}.pa{text-decoration:underline}.pg{margin-left:auto}.ph{margin-right:auto}.pi{max-width:1600px}.po{clear:both}.pq{cursor:zoom-in}.pr{z-index:auto}.pt{height:auto}.pu{margin-top:10px}.pv{max-width:728px}.py{overflow-x:auto}.pz{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.qa{padding:32px}.qb{border:1px solid #E5E5E5}.qc{line-height:1.4}.qd{margin-top:-0.2em}.qe{margin-bottom:-0.2em}.qf{white-space:pre}.qg{min-width:fit-content}.qh{line-height:1.18}.qv{margin-bottom:-0.31em}.qw{list-style-type:disc}.qx{margin-left:30px}.qy{padding-left:0px}.re{margin-bottom:26px}.rf{margin-top:6px}.rg{margin-top:8px}.rh{margin-right:8px}.ri{padding:8px 16px}.rj{border-radius:100px}.rk{transition:background 300ms ease}.rm{white-space:nowrap}.rn{border-top:none}.rt{height:52px}.ru{max-height:52px}.rv{box-sizing:content-box}.rw{position:static}.ry{max-width:155px}.se{margin-right:20px}.sk{align-items:flex-end}.sl{width:76px}.sm{height:76px}.sn{border:2px solid #F9F9F9}.so{height:72px}.sp{width:72px}.sq{margin-left:-16px}.sr{width:36px}.ss{height:36px}.st{stroke:#F2F2F2}.su{color:#F2F2F2}.sv{fill:#F2F2F2}.sw{background:#F2F2F2}.sx{border-color:#F2F2F2}.td{font-weight:500}.te{font-size:24px}.tf{line-height:30px}.tg{letter-spacing:-0.016em}.th{margin-top:16px}.ti{height:0px}.tj{border-bottom:solid 1px #E5E5E5}.tp{margin-top:72px}.tq{padding:24px 0}.tr{margin-bottom:0px}.ts{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.et:hover{background:rgba(87, 117, 162, 1)}.eu:hover{border-color:rgba(87, 117, 162, 1)}.ev:hover{cursor:pointer}.fl:hover{color:#242424}.fm:hover{fill:#242424}.fq:hover svg{fill:#242424}.ft:hover{background-color:rgba(0, 0, 0, 0.1)}.jc:hover{text-decoration:underline}.jh:hover:not(:disabled){color:rgba(87, 117, 162, 1)}.ji:hover:not(:disabled){fill:rgba(87, 117, 162, 1)}.lp:hover{fill:rgba(8, 8, 8, 1)}.me:hover{fill:#000000}.mf:hover p{color:#000000}.mi:hover{color:#000000}.ms:hover svg{color:#000000}.rl:hover{background-color:#F2F2F2}.sy:hover{background:#F2F2F2}.sz:hover{border-color:#F2F2F2}.ta:hover{cursor:wait}.tb:hover{color:#F2F2F2}.tc:hover{fill:#F2F2F2}.bd:focus-within path{fill:#242424}.lo:focus{fill:rgba(8, 8, 8, 1)}.mt:focus svg{color:#000000}.ps:focus{transform:scale(1.01)}.lt:active{border-style:none}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bw{width:64px}.cg{margin:0 64px}.cv{height:48px}.dc{margin-bottom:52px}.do{margin-bottom:48px}.ef{font-size:14px}.eg{line-height:20px}.em{font-size:13px}.eo{padding:5px 12px}.fh{display:flex}.fy{margin-bottom:68px}.gc{max-width:680px}.hm{font-size:42px}.hn{margin-top:1.19em}.ho{line-height:52px}.hp{letter-spacing:-0.011em}.ie{font-size:22px}.if{margin-top:0.92em}.ig{line-height:28px}.il{align-items:center}.kn{border-top:solid 1px #F2F2F2}.ko{border-bottom:solid 1px #F2F2F2}.kp{margin:32px 0 0}.kq{padding:3px 8px}.kz> *{margin-right:24px}.la> :last-child{margin-right:0}.ma{margin-top:0px}.mo{margin:0}.nz{font-size:24px}.oa{margin-top:1.95em}.ob{line-height:30px}.oc{letter-spacing:-0.016em}.ov{font-size:20px}.ow{margin-top:0.94em}.ox{line-height:32px}.oy{letter-spacing:-0.003em}.pf{margin-top:2.14em}.pn{margin-top:56px}.qs{margin-top:1.72em}.qt{line-height:24px}.qu{letter-spacing:0}.rd{margin-top:1.14em}.rs{margin-bottom:88px}.sd{display:inline-block}.sj{padding-top:72px}.to{margin-top:40px}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.lz{margin-top:0px}.pw{margin-left:auto}.px{text-align:center}.sc{display:inline-block}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.ly{margin-top:0px}.sb{display:inline-block}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.lw{margin-top:0px}.lx{margin-right:0px}.sa{display:inline-block}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dx{font-size:13px}.dy{line-height:20px}.eh{padding:0px 8px 1px}.fu{margin-bottom:4px}.gw{font-size:32px}.gx{margin-top:1.01em}.gy{line-height:38px}.gz{letter-spacing:-0.014em}.hs{font-size:18px}.ht{margin-top:0.79em}.hu{line-height:24px}.ih{align-items:flex-start}.jk{flex-direction:column}.jn{margin-bottom:2px}.kb{margin:24px -24px 0}.kc{padding:0}.kr> *{margin-right:8px}.ks> :last-child{margin-right:24px}.lj{margin-left:0px}.lu{margin-top:0px}.lv{margin-right:0px}.mk{margin:0}.mu{border:1px solid #F2F2F2}.mv{border-radius:99em}.mw{padding:0px 16px 0px 12px}.mx{height:38px}.my{align-items:center}.na svg{margin-right:8px}.nl{font-size:20px}.nm{margin-top:1.2em}.nn{letter-spacing:0}.oh{margin-top:0.67em}.oi{line-height:28px}.oj{letter-spacing:-0.003em}.pb{margin-top:1.56em}.pj{margin-top:40px}.qi{font-size:16px}.qj{margin-top:1.23em}.qz{margin-top:1.34em}.ro{margin-bottom:80px}.rz{display:inline-block}.sf{padding-top:48px}.tk{margin-top:32px}.mz:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ed{font-size:14px}.ee{line-height:20px}.ek{font-size:13px}.el{padding:5px 12px}.fg{display:flex}.fx{margin-bottom:68px}.gb{max-width:680px}.hi{font-size:42px}.hj{margin-top:1.19em}.hk{line-height:52px}.hl{letter-spacing:-0.011em}.ib{font-size:22px}.ic{margin-top:0.92em}.id{line-height:28px}.ik{align-items:center}.kj{border-top:solid 1px #F2F2F2}.kk{border-bottom:solid 1px #F2F2F2}.kl{margin:32px 0 0}.km{padding:3px 8px}.kx> *{margin-right:24px}.ky> :last-child{margin-right:0}.mn{margin:0}.nv{font-size:24px}.nw{margin-top:1.95em}.nx{line-height:30px}.ny{letter-spacing:-0.016em}.or{font-size:20px}.os{margin-top:0.94em}.ot{line-height:32px}.ou{letter-spacing:-0.003em}.pe{margin-top:2.14em}.pm{margin-top:56px}.qp{margin-top:1.72em}.qq{line-height:24px}.qr{letter-spacing:0}.rc{margin-top:1.14em}.rr{margin-bottom:88px}.si{padding-top:72px}.tn{margin-top:40px}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bu{width:64px}.ce{margin:0 48px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.eb{font-size:13px}.ec{line-height:20px}.ej{padding:0px 8px 1px}.fw{margin-bottom:68px}.ga{max-width:680px}.he{font-size:42px}.hf{margin-top:1.19em}.hg{line-height:52px}.hh{letter-spacing:-0.011em}.hy{font-size:22px}.hz{margin-top:0.92em}.ia{line-height:28px}.ij{align-items:center}.kf{border-top:solid 1px #F2F2F2}.kg{border-bottom:solid 1px #F2F2F2}.kh{margin:32px 0 0}.ki{padding:3px 8px}.kv> *{margin-right:24px}.kw> :last-child{margin-right:0}.mm{margin:0}.nr{font-size:24px}.ns{margin-top:1.95em}.nt{line-height:30px}.nu{letter-spacing:-0.016em}.on{font-size:20px}.oo{margin-top:0.94em}.op{line-height:32px}.oq{letter-spacing:-0.003em}.pd{margin-top:2.14em}.pl{margin-top:56px}.qm{margin-top:1.72em}.qn{line-height:24px}.qo{letter-spacing:0}.rb{margin-top:1.14em}.rq{margin-bottom:88px}.sh{padding-top:72px}.tm{margin-top:40px}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bt{width:24px}.cd{margin:0 24px}.cs{height:40px}.cz{margin-bottom:44px}.dl{margin-bottom:32px}.dz{font-size:13px}.ea{line-height:20px}.ei{padding:0px 8px 1px}.fv{margin-bottom:4px}.ha{font-size:32px}.hb{margin-top:1.01em}.hc{line-height:38px}.hd{letter-spacing:-0.014em}.hv{font-size:18px}.hw{margin-top:0.79em}.hx{line-height:24px}.ii{align-items:flex-start}.jl{flex-direction:column}.jo{margin-bottom:2px}.kd{margin:24px 0 0}.ke{padding:0}.kt> *{margin-right:8px}.ku> :last-child{margin-right:8px}.lk{margin-left:0px}.ml{margin:0}.nb{border:1px solid #F2F2F2}.nc{border-radius:99em}.nd{padding:0px 16px 0px 12px}.ne{height:38px}.nf{align-items:center}.nh svg{margin-right:8px}.no{font-size:20px}.np{margin-top:1.2em}.nq{letter-spacing:0}.ok{margin-top:0.67em}.ol{line-height:28px}.om{letter-spacing:-0.003em}.pc{margin-top:1.56em}.pk{margin-top:40px}.qk{font-size:16px}.ql{margin-top:1.23em}.ra{margin-top:1.34em}.rp{margin-bottom:80px}.sg{padding-top:48px}.tl{margin-top:32px}.ng:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE" media="print">.rx{display:none}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.jy{max-height:none}</style><style type="text/css" data-fela-rehydration="538" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.pp{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="l m n o c"><div class="p q r s t u v w x i d y z"><a class="du ag dv bf ak b am an ao ap aq ar as at s u w i d q dw z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fffde295c3558&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">Open in app<svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="none" viewBox="0 0 10 10" class="dt"><path fill="currentColor" d="M.985 8.485a.375.375 0 1 0 .53.53zM8.75 1.25h.375A.375.375 0 0 0 8.75.875zM8.375 6.5a.375.375 0 1 0 .75 0zM3.5.875a.375.375 0 1 0 0 .75zm-1.985 8.14 7.5-7.5-.53-.53-7.5 7.5zm6.86-7.765V6.5h.75V1.25zM3.5 1.625h5.25v-.75H3.5z"></path></svg></a><div class="ab q"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="bf b dx dy eh dz ea ei eb ec ej ek ee el em eg eo ep eq er es et eu ev ew ex ey ez fa fb fc fd bm fe ff" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="ax l"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" href="https://medium.com/?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="719" height="160" fill="none" viewBox="0 0 719 160" class="au av aw"><path fill="#242424" d="m174.104 9.734.215-.047V8.02H130.39L89.6 103.89 48.81 8.021H1.472v1.666l.212.047c8.018 1.81 12.09 4.509 12.09 14.242V137.93c0 9.734-4.087 12.433-12.106 14.243l-.212.047v1.671h32.118v-1.665l-.213-.048c-8.018-1.809-12.089-4.509-12.089-14.242V30.586l52.399 123.305h2.972l53.925-126.743V140.75c-.687 7.688-4.721 10.062-11.982 11.701l-.215.05v1.652h55.948v-1.652l-.215-.05c-7.269-1.639-11.4-4.013-12.087-11.701l-.037-116.774h.037c0-9.733 4.071-12.432 12.087-14.242m25.555 75.488c.915-20.474 8.268-35.252 20.606-35.507 3.806.063 6.998 1.312 9.479 3.714 5.272 5.118 7.751 15.812 7.368 31.793zm-.553 5.77h65.573v-.275c-.186-15.656-4.721-27.834-13.466-36.196-7.559-7.227-18.751-11.203-30.507-11.203h-.263c-6.101 0-13.584 1.48-18.909 4.16-6.061 2.807-11.407 7.003-15.855 12.511-7.161 8.874-11.499 20.866-12.554 34.343q-.05.606-.092 1.212a50 50 0 0 0-.065 1.151 85.807 85.807 0 0 0-.094 5.689c.71 30.524 17.198 54.917 46.483 54.917 25.705 0 40.675-18.791 44.407-44.013l-1.886-.664c-6.557 13.556-18.334 21.771-31.738 20.769-18.297-1.369-32.314-19.922-31.042-42.395m139.722 41.359c-2.151 5.101-6.639 7.908-12.653 7.908s-11.513-4.129-15.418-11.63c-4.197-8.053-6.405-19.436-6.405-32.92 0-28.067 8.729-46.22 22.24-46.22 5.657 0 10.111 2.807 12.236 7.704zm43.499 20.008c-8.019-1.897-12.089-4.722-12.089-14.951V1.309l-48.716 14.353v1.757l.299-.024c6.72-.543 11.278.386 13.925 2.83 2.072 1.915 3.082 4.853 3.082 8.987v18.66c-4.803-3.067-10.516-4.56-17.448-4.56-14.059 0-26.909 5.92-36.176 16.672-9.66 11.205-14.767 26.518-14.767 44.278-.003 31.72 15.612 53.039 38.851 53.039 13.595 0 24.533-7.449 29.54-20.013v16.865h43.711v-1.746zM424.1 19.819c0-9.904-7.468-17.374-17.375-17.374-9.859 0-17.573 7.632-17.573 17.374s7.721 17.374 17.573 17.374c9.907 0 17.375-7.47 17.375-17.374m11.499 132.546c-8.019-1.897-12.089-4.722-12.089-14.951h-.035V43.635l-43.714 12.551v1.705l.263.024c9.458.842 12.047 4.1 12.047 15.152v81.086h43.751v-1.746zm112.013 0c-8.018-1.897-12.089-4.722-12.089-14.951V43.635l-41.621 12.137v1.71l.246.026c7.733.813 9.967 4.257 9.967 15.36v59.279c-2.578 5.102-7.415 8.131-13.274 8.336-9.503 0-14.736-6.419-14.736-18.073V43.638l-43.714 12.55v1.703l.262.024c9.459.84 12.05 4.097 12.05 15.152v50.17a56.3 56.3 0 0 0 .91 10.444l.787 3.423c3.701 13.262 13.398 20.197 28.59 20.197 12.868 0 24.147-7.966 29.115-20.43v17.311h43.714v-1.747zm169.818 1.788v-1.749l-.213-.05c-8.7-2.006-12.089-5.789-12.089-13.49v-63.79c0-19.89-11.171-31.761-29.883-31.761-13.64 0-25.141 7.882-29.569 20.16-3.517-13.01-13.639-20.16-28.606-20.16-13.146 0-23.449 6.938-27.869 18.657V43.643L545.487 55.68v1.715l.263.024c9.345.829 12.047 4.181 12.047 14.95v81.784h40.787v-1.746l-.215-.053c-6.941-1.631-9.181-4.606-9.181-12.239V66.998c1.836-4.289 5.537-9.37 12.853-9.37 9.086 0 13.692 6.296 13.692 18.697v77.828h40.797v-1.746l-.215-.053c-6.94-1.631-9.18-4.606-9.18-12.239V75.066a42 42 0 0 0-.578-7.26c1.947-4.661 5.86-10.177 13.475-10.177 9.214 0 13.691 6.114 13.691 18.696v77.828z"></path></svg></a><div class="ax h"><div class="ab ay az ba bb q bc bd"><div class="bm" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bn bo ab"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ay be bf bg z bh bi bj bk bl" placeholder="Search" value=""/></div></div></div><div class="h k w fg fh"><div class="fi ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerWriteButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---two_column_layout_nav-----------------------new_post_topnav-----------" rel="noopener follow"><div class="bf b bg z du fj fk ab q fl fm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Write"><path fill="currentColor" d="M14 4a.5.5 0 0 0 0-1zm7 6a.5.5 0 0 0-1 0zm-7-7H4v1h10zM3 4v16h1V4zm1 17h16v-1H4zm17-1V10h-1v10zm-1 1a1 1 0 0 0 1-1h-1zM3 20a1 1 0 0 0 1 1v-1zM4 3a1 1 0 0 0-1 1h1z"></path><path stroke="currentColor" d="m17.5 4.5-8.458 8.458a.25.25 0 0 0-.06.098l-.824 2.47a.25.25 0 0 0 .316.316l2.47-.823a.25.25 0 0 0 .098-.06L19.5 6.5m-2-2 2.323-2.323a.25.25 0 0 1 .354 0l1.646 1.646a.25.25 0 0 1 0 .354L19.5 6.5m-2-2 2 2"></path></svg><div class="dt l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fi ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSearchButton" href="https://medium.com/search?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="bf b bg z du fj fk ab q fl fm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Search"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div></a></div></div><div class="fi h k j"><div class="ab q"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="bf b dx dy eh dz ea ei eb ec ej ek ee el em eg eo ep eq er es et eu ev ew ex ey ez fa fb fc fd bm fe ff" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="ax l"><p class="bf b dx dy dz ea eb ec ed ee ef eg du"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ay fn am ab q ao fo fp fq" aria-label="user options menu" data-testid="headerUserIcon"><div class="l fj"><img alt="" class="l fd by bz ca cx" src="https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"/><div class="fr by l bz ca fs n ay ft"></div></div></button></div></div></div><div class="l"><div class="fu fv fw fx fy l"><div class="ab cb"><div class="ci bh fz ga gb gc"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="fs gi gj gk gl gm"></div><div class="gn go gp gq gr"><div class="ab cb"><div class="ci bh fz ga gb gc"><div><h1 id="a83e" class="pw-post-title gs gt gu bf gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq bk" data-testid="storyTitle">An Intuitive 101 Guide to Vector Embeddings</h1></div><div><h2 id="28bc" class="pw-subtitle-paragraph hr gt gu bf b hs ht hu hv hw hx hy hz ia ib ic id ie if ig cq du">Vector embeddings matter as fundamental building blocks for Generative AI</h2><div><div class="speechify-ignore ab cp"><div class="speechify-ignore bh l"><div class="ih ii ij ik il ab"><div><div class="ab im"><a href="https://medium.com/@2twitme?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><div><div class="bm" aria-hidden="false"><div class="l in io by ip iq"><div class="l fj"><img alt="Jules S. Damji" class="l fd by dd de cx" src="https://miro.medium.com/v2/resize:fill:88:88/0*hIS9LgEB75e1xfzz.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"/><div class="ir by l dd de fs n is ft"></div></div></div></div></div></a><a href="https://ai.gopubby.com/?source=post_page-----ffde295c3558--------------------------------" rel="noopener  ugc nofollow"><div class="it ab fj"><div><div class="bm" aria-hidden="false"><div class="l iu iv by ip iw"><div class="l fj"><img alt="AI Advances" class="l fd by br ix cx" src="https://miro.medium.com/v2/resize:fill:48:48/1*R8zEd59FDf0l8Re94ImV0Q.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto"/><div class="ir by l br ix fs n is ft"></div></div></div></div></div></div></a></div></div><div class="bn bh l"><div class="ab"><div style="flex:1"><span class="bf b bg z bk"><div class="iy ab q"><div class="ab q iz"><div class="ab q"><div><div class="bm" aria-hidden="false"><p class="bf b ja jb bk"><a class="af ag ah ai aj ak al am an ao ap aq ar jc" data-testid="authorName" href="https://medium.com/@2twitme?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow">Jules S. Damji</a></p></div></div></div><span class="jd je" aria-hidden="true"><span class="bf b bg z du">·</span></span><p class="bf b ja jb du"><span><a class="jf jg ah ai aj ak al am an ao ap aq ar ex jh ji" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F603ab1741c22&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;user=Jules+S.+Damji&amp;userId=603ab1741c22&amp;source=post_page-603ab1741c22----ffde295c3558---------------------post_header-----------" rel="noopener follow">Follow</a></span></p></div></div></span></div></div><div class="l jj"><span class="bf b bg z du"><div class="ab cn jk jl jm"><div class="jn jo ab"><div class="bf b bg z du ab jp"><span class="jq l jj">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" data-testid="publicationName" href="https://ai.gopubby.com/?source=post_page-----ffde295c3558--------------------------------" rel="noopener  ugc nofollow"><p class="bf b bg z jr js jt ju jv jw jx jy bk">AI Advances</p></a></div></div></div><div class="h k"><span class="jd je" aria-hidden="true"><span class="bf b bg z du">·</span></span></div></div><span class="bf b bg z du"><div class="ab ae"><span data-testid="storyReadTime">9 min read</span><div class="jz ka l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bf b bg z du">·</span></span></div><span data-testid="storyPublishDate">Mar 22, 2024</span></div></span></div></span></div></div></div><div class="ab cp kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq"><div class="h k w fg fh q"><div class="lg l"><div class="ab q lh li"><div class="pw-multi-vote-icon fj jq lj lk ll"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fai-advances%2Fffde295c3558&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;user=Jules+S.+Damji&amp;userId=603ab1741c22&amp;source=-----ffde295c3558---------------------clap_footer-----------" rel="noopener follow"><div><div class="bm" aria-hidden="false"><div class="lm ao ln lo lp lq am lr ls lt ll"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="bf b dv z du"><span class="mb">--</span></p></div></div></div><div><div class="bm" aria-hidden="false"><button class="ao lm mc md ab q fk me mf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="mg"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg></button></div></div></div><div class="ab q kr ks kt ku kv kw kx ky kz la lb lc ld le lf"><div class="mh k j i d"></div><div class="h k"><div><div class="bm" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fffde295c3558&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;source=-----ffde295c3558---------------------bookmark_footer-----------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mi" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="fd mj cn"><div class="l ae"><div class="ab cb"><div class="mk ml mm mn mo mp ci bh"><div class="ab"><div class="bm bh" aria-hidden="false"><div><div class="bm" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af fk ah ai aj ak al mq an ao ap ex mr ms mf mt mu mv mw mx s my mz na nb nc nd ne u nf ng nh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"></path></svg><div class="j i d"><p class="bf b bg z du">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af fk ah ai aj ak al mq an ao ap ex mr ms mf mt mu mv mw mx s my mz na nb nc nd ne u nf ng nh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg><div class="j i d"><p class="bf b bg z du">Share</p></div></button></div></div></div></div></div></div></div></div></div><h1 id="8835" class="ni nj gu bf nk nl nm hu nn no np hx nq nr ns nt nu nv nw nx ny nz oa ob oc od bk">Introduction</h1><p id="4e61" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">Embeddings, particularly text or word embeddings, are not novel today. Bengio et al. originally coined the term ‘word embeddings’ in 2003, training them in a Neural Probabilistic Language Model along with the model’s parameters. [<a class="af pa" href="https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" rel="noopener ugc nofollow" target="_blank">1</a>] Since then, their representation, algorithms, and models to compute embeddings are predominantly used in natural language processing (NLP) tasks.</p><p id="dddf" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Originally confined to use cases for semantic textual searches, rather than traditional string or keyword pattern matching, embeddings are now used in other semantic search engines for images, audio, and videos. In more recent times, they have gained immense prominence and are widely utilized in generative AI applications.</p><p id="776e" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Conceptually, Kevin Henner describes vectors as “an embedding [in vector] space or latent space, as a manifold in which similar items are positioned closer to one another than less similar items. In this case, sentences [or data objects] that are semantically similar should have similar embedded vectors and thus be closer together in space.” [<a class="af pa" href="https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/" rel="noopener ugc nofollow" target="_blank">2</a>]</p><p id="59a0" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Similarly, Nathan Crone defines a vector embedding simply as “… a vector created as the numerical representation of typically non-numerical data objects. Embeddings capture the inherent properties and relationships of the original data in a condensed [or dense] format and are often used in machine learning use cases,” [<a class="af pa" href="https://vectordatabase.substack.com/p/vector-embeddings-101-the-new-building" rel="noopener ugc nofollow" target="_blank">3</a>] as depicted in <strong class="og gv">Figure 1</strong>.</p><figure class="pj pk pl pm pn po pg ph paragraph-image"><div role="button" tabindex="0" class="pp pq fj pr bh ps"><div class="pg ph pi"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*jOGKVlYLxPTmOLal 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*jOGKVlYLxPTmOLal 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*jOGKVlYLxPTmOLal 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*jOGKVlYLxPTmOLal 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*jOGKVlYLxPTmOLal 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*jOGKVlYLxPTmOLal 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jOGKVlYLxPTmOLal 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*jOGKVlYLxPTmOLal 640w, https://miro.medium.com/v2/resize:fit:720/0*jOGKVlYLxPTmOLal 720w, https://miro.medium.com/v2/resize:fit:750/0*jOGKVlYLxPTmOLal 750w, https://miro.medium.com/v2/resize:fit:786/0*jOGKVlYLxPTmOLal 786w, https://miro.medium.com/v2/resize:fit:828/0*jOGKVlYLxPTmOLal 828w, https://miro.medium.com/v2/resize:fit:1100/0*jOGKVlYLxPTmOLal 1100w, https://miro.medium.com/v2/resize:fit:1400/0*jOGKVlYLxPTmOLal 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bh mp pt c" width="700" height="335" loading="lazy" role="presentation"/></picture></div></div><figcaption class="pu ff pv pg ph pw px bf b bg z du"><strong class="bf nk">Figure 1</strong>: Documents transformed into embeddings and projected into vector space [<a class="af pa" href="https://datasciencedojo.com/blog/vector-embeddings-generative-ai/" rel="noopener ugc nofollow" target="_blank">4</a>]</figcaption></figure><p id="3627" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">In essence, we can describe embeddings as high-dimensional cardinal data reduced or condensed into two or three lower dimensional latent vector spaces. As vectors projected into a latent space, computers can then perform fast mathematical operations such as measuring distances, calculating similarities, and performing transformations on an array or a matrix of vectors.</p><p id="5d91" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Python’s <a class="af pa" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank">numpy</a> and <a class="af pa" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank">spacy</a> libraries offer efficient vector operations and transformations, particularly for NLP tasks, such as computing the distance, evaluating proximity of vectors close to each other, or employing trained models to generate embeddings.</p><p id="02ef" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">In this article, we explore the fundamental concept of vector embeddings, why they matter, what they are, and what they are used for. We won’t delve or dive into how embedding models are trained.</p><h1 id="74f6" class="ni nj gu bf nk nl nm hu nn no np hx nq nr ns nt nu nv nw nx ny nz oa ob oc od bk">Why embeddings matter</h1><p id="2944" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">Embeddings matter because they capture the essence and meaning of data in a numerical form. As such computers can deal efficiently with numerical representation of any structured or unstructured data. Generated as data’s numerical vectors and projected into a latent multi-dimensional space, they capture and preserve data’s semantic meaning. Their essence, then, can be persisted in purpose-built data stores called vector databases.</p><figure class="pj pk pl pm pn po pg ph paragraph-image"><div role="button" tabindex="0" class="pp pq fj pr bh ps"><div class="pg ph pi"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*VGQaay1U0-9NfA2D 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*VGQaay1U0-9NfA2D 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*VGQaay1U0-9NfA2D 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*VGQaay1U0-9NfA2D 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*VGQaay1U0-9NfA2D 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*VGQaay1U0-9NfA2D 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VGQaay1U0-9NfA2D 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*VGQaay1U0-9NfA2D 640w, https://miro.medium.com/v2/resize:fit:720/0*VGQaay1U0-9NfA2D 720w, https://miro.medium.com/v2/resize:fit:750/0*VGQaay1U0-9NfA2D 750w, https://miro.medium.com/v2/resize:fit:786/0*VGQaay1U0-9NfA2D 786w, https://miro.medium.com/v2/resize:fit:828/0*VGQaay1U0-9NfA2D 828w, https://miro.medium.com/v2/resize:fit:1100/0*VGQaay1U0-9NfA2D 1100w, https://miro.medium.com/v2/resize:fit:1400/0*VGQaay1U0-9NfA2D 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bh mp pt c" width="700" height="468" loading="lazy" role="presentation"/></picture></div></div><figcaption class="pu ff pv pg ph pw px bf b bg z du"><strong class="bf nk">Figure 2</strong>: Courtesy of DALL-E 3 rendering a vector database with myriad data embeddings</figcaption></figure><p id="6adb" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Embeddings matter because the recent emergence of scalable purpose-built vector databases serve scalable vector-based computational needs for tasks common to NLP and generative AI.</p><p id="6d50" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">In a post <a class="af pa" href="https://a16z.com/emerging-architectures-for-llm-applications/" rel="noopener ugc nofollow" target="_blank">Emerging Architectures for LLM Applications</a>, based on conversations with AI startup founders and engineers, Andreessen Horowitz report that vector databases play a pivotal role as part of the preprocessing pipeline for emerging generative AI application stack, allowing for efficient storage, retrieval, comparison, searches, and computation of vector embeddings at scale. [<a class="af pa" href="https://a16z.com/emerging-architectures-for-llm-applications/" rel="noopener ugc nofollow" target="_blank">5</a>]</p><p id="710b" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Asked in simple terms, what form and format do these vector embeddings take? Let’s look at a simple example to get an intuition.</p><h1 id="cc71" class="ni nj gu bf nk nl nm hu nn no np hx nq nr ns nt nu nv nw nx ny nz oa ob oc od bk">What are vectors embedding</h1><p id="fc6c" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">From above, it follows that a vector embedding is a single dimensional or multi-dimensional array of sequence of numbers, where each number may correspond to data’s semantic meaning in relation to the other numbers in the sequence.</p><p id="1b2a" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">For example, assume the vector_1 = [0.5, 1.75, -2, …, 0.9] could capture the semantic meaning of “The cat sat on a cushy mat.” Another vector, vector_2 = [0.5, 1.65, -1, …, 0.9], could capture the meaning of “The cat stretched and laid down on a furry mat.”</p><p id="ea1c" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">The above two vector embeddings are deemed relatively similar if they possess semantic similarity. In the above case, this semantic similarity of two vectors is expressed as the shortest distance between them when they are projected in a vector space. It follows that we can confidently assert that similar vector embeddings will congregate into clusters, and, therefore, we can fetch all its N nearest neighbors within a cluster of similar vector embeddings. See <strong class="og gv">Figure 3</strong>.</p><figure class="pj pk pl pm pn po pg ph paragraph-image"><div role="button" tabindex="0" class="pp pq fj pr bh ps"><div class="pg ph pi"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*jL-xIBkXNqlvF1UD 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*jL-xIBkXNqlvF1UD 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*jL-xIBkXNqlvF1UD 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*jL-xIBkXNqlvF1UD 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*jL-xIBkXNqlvF1UD 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*jL-xIBkXNqlvF1UD 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jL-xIBkXNqlvF1UD 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*jL-xIBkXNqlvF1UD 640w, https://miro.medium.com/v2/resize:fit:720/0*jL-xIBkXNqlvF1UD 720w, https://miro.medium.com/v2/resize:fit:750/0*jL-xIBkXNqlvF1UD 750w, https://miro.medium.com/v2/resize:fit:786/0*jL-xIBkXNqlvF1UD 786w, https://miro.medium.com/v2/resize:fit:828/0*jL-xIBkXNqlvF1UD 828w, https://miro.medium.com/v2/resize:fit:1100/0*jL-xIBkXNqlvF1UD 1100w, https://miro.medium.com/v2/resize:fit:1400/0*jL-xIBkXNqlvF1UD 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bh mp pt c" width="700" height="303" loading="lazy" role="presentation"/></picture></div></div><figcaption class="pu ff pv pg ph pw px bf b bg z du"><strong class="bf nk">Figure 3. </strong>Similar vector embeddings projected in 2D space clustered together [<a class="af pa" href="https://datasciencedojo.com/blog/vector-embeddings-generative-ai/" rel="noopener ugc nofollow" target="_blank">6]</a></figcaption></figure><p id="6f4a" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">To compute the shortest distance between two projected vectors, cosine similarity is a common method; another one is Euclidean distance. <a class="af pa" href="https://en.wikipedia.org/wiki/Cosine_similarity)" rel="noopener ugc nofollow" target="_blank">Cosine similarity</a> measures the cosine of the angle between two vectors and ranges from -1 to 1, where 1 means the vectors are identical, -1 means they are opposites, and 0 means they are orthogonal (i.e., unrelated). [<a class="af pa" href="https://causewriter.ai/courses/ai-explainers/lessons/vector-embedding/" rel="noopener ugc nofollow" target="_blank">7</a>]</p><figure class="pj pk pl pm pn po pg ph paragraph-image"><div role="button" tabindex="0" class="pp pq fj pr bh ps"><div class="pg ph pi"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*mdpXDa066Gez0En7 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*mdpXDa066Gez0En7 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*mdpXDa066Gez0En7 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*mdpXDa066Gez0En7 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*mdpXDa066Gez0En7 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*mdpXDa066Gez0En7 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mdpXDa066Gez0En7 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*mdpXDa066Gez0En7 640w, https://miro.medium.com/v2/resize:fit:720/0*mdpXDa066Gez0En7 720w, https://miro.medium.com/v2/resize:fit:750/0*mdpXDa066Gez0En7 750w, https://miro.medium.com/v2/resize:fit:786/0*mdpXDa066Gez0En7 786w, https://miro.medium.com/v2/resize:fit:828/0*mdpXDa066Gez0En7 828w, https://miro.medium.com/v2/resize:fit:1100/0*mdpXDa066Gez0En7 1100w, https://miro.medium.com/v2/resize:fit:1400/0*mdpXDa066Gez0En7 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bh mp pt c" width="700" height="224" loading="lazy" role="presentation"/></picture></div></div><figcaption class="pu ff pv pg ph pw px bf b bg z du"><strong class="bf nk">Figure 4:</strong> Cosine similarity is the smallest angle and shortest distance between two vectors [<a class="af pa" href="https://www.learndatasci.com/glossary/cosine-similarity/" rel="noopener ugc nofollow" target="_blank">8</a>,<a class="af pa" href="https://www.learndatasci.com/glossary/cosine-similarity/" rel="noopener ugc nofollow" target="_blank">9</a>]</figcaption></figure><p id="d5c8" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Let’s take the above simple example of the “cat on the mat” a bit further and compute its cosine similarity to ascertain if they are semantically similar. We will use the numpy library.</p><pre class="pj pk pl pm pn py pz qa bp qb bb bk"><span id="1898" class="qc nj gu pz b bg qd qe l qf qg">import numpy as np<br/><br/>v1 = np.array([0.5, 1.75, -2, ..., 0.9])  # Replace &#x27;...&#x27; with the remaining elements<br/>v2 = np.array([0.5, 1.65, -1, ..., 0.9])  # Replace &#x27;...&#x27; with the remaining elements<br/><br/># Compute the length of each vector<br/>length_v1 = np.linalg.norm(v1)<br/>length_v2 = np.linalg.norm(v2)<br/><br/>print(&quot;Length of v1:&quot;, length_v1)  # Length of v1: 2.85<br/>print(&quot;Length of v2:&quot;, length_v2)  # Length of v2: 2.17<br/><br/># Compute cosine similarity<br/>cos_sim = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))<br/><br/>print(&quot;Cosine similarity:&quot;, cos_sim) # Cosine similarity: 0.954</span></pre><p id="f53b" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Since cosine similarity of 0.954 =~ 1, they are similar in semantics. Another way to compute cosine similarity using an embedding model encoder:</p><pre class="pj pk pl pm pn py pz qa bp qb bb bk"><span id="8603" class="qc nj gu pz b bg qd qe l qf qg">from sentence_transformers import SentenceTransformer<br/><br/>model = SentenceTransformer(&#x27;bert-base-nli-mean-tokens&#x27;)<br/><br/>#input sentences<br/>sentences = [&#x27;The cat sat on a mushy mat&#x27;,<br/>             &#x27;The cat stretched and laid down on a furry mat&#x27;]<br/><br/>#encode sentences<br/>embeddings = model.encode(sentences)<br/><br/>#output embeddings<br/>for phrase, embedding in zip(sentences, embeddings):<br/>    print(&quot;Phrase:&quot;, phrase)<br/>    print(&quot;Embedding shape:&quot;, embedding.shape) <br/>    print(&quot;Embedding:&quot;, embedding[0:5])<br/>print(&quot;--&quot; * 40)<br/><br/># compute cosine similarity<br/>from sklearn.metrics.pairwise import cosine_similarity<br/><br/>cs = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]<br/>print (f&quot;Cosine similarity: {cs:.4f}&quot;)<br/><br/>#ouput from above<br/>Phrase: The cat sat on a mushy mat<br/>Embedding shape: (768,)<br/>Embedding: [ 0.00477061  0.43979567 -0.01233868 -0.3416704  -0.24160706]<br/>Phrase: The cat stretched and laid down on a furry mat<br/>Embedding shape: (768,)<br/>Embedding: [ 0.10522226 -0.06775486  0.09200469 -0.78158903 -0.26045752]<br/>------------------------------------------------------------------------<br/>Cosine similarity: 0.9192</span></pre><p id="3a9e" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Vector embeddings are not restricted only to textual data. Other forms of data can also be converted to vector embeddings.</p><h1 id="6ce6" class="ni nj gu bf nk nl nm hu nn no np hx nq nr ns nt nu nv nw nx ny nz oa ob oc od bk">Types of vector embeddings: text, video, image, audio, and time</h1><p id="2482" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">In the digital domain, data exists in myriad formats. And to process this data, to make sense of data, or to use data to train a model for a specific task, we need vector embeddings for each respective data type. So multi-model vector embeddings can be created for various types of data, including text, video, image, audio, and time. Today, each type of vector embedding serves a specific use case in generative AI applications. Here are a few examples:</p><h2 id="4dda" class="qh nj gu bf nk qi qj dy nn qk ql ea nq on qm qn qo or qp qq qr ov qs qt qu qv bk">Text Embeddings</h2><p id="2477" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">Text embeddings represent textual data, such as sentences, documents, or words, as numerical vectors. Since these vectors capture the semantic meaning of the text, they can be used for tasks like semantic search, text classification, and language generation.</p><h2 id="ce92" class="qh nj gu bf nk qi qj dy nn qk ql ea nq on qm qn qo or qp qq qr ov qs qt qu qv bk">Video and Image Embeddings</h2><p id="d9a2" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">Video embeddings encode video data as numerical vectors. Capturing visual features and temporal information from the video frames, video embeddings are useful for tasks such as video recommendation, video search, and video summarization.</p><p id="d538" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Similarly, image embeddings capture visual features like shape, texture, and color and are useful for image recognition and comparison.</p><h2 id="0506" class="qh nj gu bf nk qi qj dy nn qk ql ea nq on qm qn qo or qp qq qr ov qs qt qu qv bk">Audio Embeddings</h2><p id="5362" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">Audio embeddings capture audio data, including speech or music, as numerical vectors, incorporating acoustic features and temporal patterns in the audio. As such, they can be used in tasks, including speech recognition, music recommendation, speech imitation, and audio similarity matching.</p><h2 id="0b31" class="qh nj gu bf nk qi qj dy nn qk ql ea nq on qm qn qo or qp qq qr ov qs qt qu qv bk">Time Embeddings</h2><p id="3ec7" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">Time embeddings represent temporal data, such as timestamps or time series. These numerical vectors capture the temporal patterns and relationships in the data. They are useful for tasks like time series forecasting, event detection, and anomaly detection in temporal data.</p><p id="072c" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">How does all this magical transformation work? 🧙‍♀️</p><h1 id="4d1e" class="ni nj gu bf nk nl nm hu nn no np hx nq nr ns nt nu nv nw nx ny nz oa ob oc od bk">How vector embeddings are created</h1><p id="d238" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">Vector embeddings are created through machine learning. Initially, a specialized model is trained for specific data types. This model learns to convert diverse training data into numerical vectors. Once trained, the model can generate vector embeddings for your data, taking specific data as input and producing vector embedding as output — and vice versa.</p><p id="79ef" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">While the actual process of training a specific model is beyond the scope of this discussion, <a class="af pa" href="https://link.springer.com/article/10.1007/s41060-021-00242-8" rel="noopener ugc nofollow" target="_blank">plenty of literature describe,</a> at length and in mathematical details, how the embedding models are trained, the respective training data marshaled and employed, and the underlying neural network architecture used.</p><p id="7f59" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">However, it’s worth noting that some of these models are readily accessible for your use. They encode your data into vector embeddings and vice versa. Several of these multi-modal models have been instrumental in developing advanced NLP and semantic search applications. Notable examples include Google Language Translation, image identification, and classification.</p><ul class=""><li id="8547" class="oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz qw qx qy bk"><a class="af pa" href="https://www.tensorflow.org/text/tutorials/word2vec" rel="noopener ugc nofollow" target="_blank">Word2vec</a></li><li id="dcf3" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><a class="af pa" href="https://codeblockhub.com/python/glove-models-python/" rel="noopener ugc nofollow" target="_blank">GloVe</a></li><li id="9fa7" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><a class="af pa" href="https://github.com/facebookresearch/fastText" rel="noopener ugc nofollow" target="_blank">FastText</a></li><li id="5541" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><a class="af pa" href="https://blog.research.google/2018/11/open-sourcing-bert-state-of-art-pre.html)" rel="noopener ugc nofollow" target="_blank">BERT</a></li><li id="0233" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><a class="af pa" href="https://en.wikipedia.org/wiki/ELMo" rel="noopener ugc nofollow" target="_blank">ELMo</a></li><li id="824b" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><a class="af pa" href="https://openai.com/research/clip" rel="noopener ugc nofollow" target="_blank">CLIP</a></li></ul><p id="28b7" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Adding to the collection of embedding models, other AI model vendors such as <a class="af pa" href="https://huggingface.co/models?other=embeddings%29" rel="noopener ugc nofollow" target="_blank">HuggingFace</a>, <a class="af pa" href="https://txt.cohere.com/introducing-embed-v3/" rel="noopener ugc nofollow" target="_blank">Cohere</a>, <a class="af pa" href="https://docs.databricks.com/en/generative-ai/create-query-vector-search.html" rel="noopener ugc nofollow" target="_blank">Databricks</a>, <a class="af pa" href="https://www.pinecone.io/models/" rel="noopener ugc nofollow" target="_blank">Pinecone</a>, and <a class="af pa" href="https://www.pinecone.io/learn/openai-embeddings-v3" rel="noopener ugc nofollow" target="_blank">OpenAI</a> offer embedding models as a service. Additionally, purpose-built and vector-based storage vendors like <a class="af pa" href="https://www.pinecone.io/product/" rel="noopener ugc nofollow" target="_blank">Pinecone</a> offer scalable and enterprise-grade vector databases for storage and retrieval.</p><h1 id="972b" class="ni nj gu bf nk nl nm hu nn no np hx nq nr ns nt nu nv nw nx ny nz oa ob oc od bk">How vector embeddings are used today</h1><p id="65f9" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">It’s no secret that embeddings matter (as mentioned above) and have become pervasive because of deep learning and large language models (LLMs) technologies. More recently, they’ve become fundamental building blocks in generative AI applications, in which data is preprocessed, represented, computed, stored, sand presented to large language models for generating responses. They are at the core of how data is consumed in these technologies.</p><p id="3064" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Today, its use cases extends to:</p><ul class=""><li id="dfff" class="oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz qw qx qy bk"><strong class="og gv">semantic searches</strong>: sophisticated search engines go beyond just keyword or pattern matching; they include other data types — images, audio and video — allowing search across multiple data formats for semantic similarities.</li><li id="b114" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><strong class="og gv">recommendation systems:</strong> capture embeddings of articles, products, images, and recommend matching or similar items selected by the users during their perusal of web content.</li><li id="162b" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><strong class="og gv">anomaly detection</strong>: create an embedding of a target entity that does not match any existing entities stored in a vector database, indicating the target item as an anomaly.</li><li id="ad47" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><strong class="og gv">image search, retrieval, and classification</strong>: image similarity is a common use case in various scenarios, including nefarious surveillance. <a class="af pa" href="https://towardsdatascience.com/clip-model-and-the-importance-of-multimodal-embeddings-1c8f6b13bf72" rel="noopener" target="_blank">CLIP</a> models are used for identifying images using natural language descriptions.</li><li id="30d4" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><strong class="og gv">content generation</strong>: detect similarity of a social post, including offensive images, to known examples of abuse stored as embeddings in an indexed vector database. <a class="af pa" href="https://towardsdatascience.com/clip-model-and-the-importance-of-multimodal-embeddings-1c8f6b13bf72" rel="noopener" target="_blank">CLIP</a> models can identify images and filter harmful content.</li><li id="9a67" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><strong class="og gv">spam filtering or classification</strong>: classify emails as examples of spam mail.</li><li id="3d45" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><strong class="og gv">conversational agent</strong>: match existing embeddings in an indexed vector database that are semantically close to the users’ messages or queries.</li><li id="8d1b" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk"><strong class="og gv">retrieval augmentation generation</strong>: use proprietary data, combined with LLMs, for an authoritative generated AI results, with more factual accuracy and less hallucination.</li></ul><p id="e0cb" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">All in all, vector embeddings are crucial today for the above use cases and are immensely powerful and useful; their applications are at the core of numerous semantic search technologies and generative AI applications. For example, Pinecone tabulates some of the example use cases. [10]</p><h1 id="c54c" class="ni nj gu bf nk nl nm hu nn no np hx nq nr ns nt nu nv nw nx ny nz oa ob oc od bk">How to use embeddings: semantic search application using a vector database</h1><p id="0fc0" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">For a quick, getting-started version of how to use vector embeddings for semantic search with a Pinecone vector database, checkout both <a class="af pa" href="https://github.com/dmatrix/genai-cookbook/blob/main/embeddings-and-vectordbs/1_pinecone_semantic_search_example.ipynb" rel="noopener ugc nofollow" target="_blank">notebook</a> and <a class="af pa" href="https://github.com/dmatrix/genai-cookbook/blob/main/embeddings-and-vectordbs/pinecone_semantic_search_example.py" rel="noopener ugc nofollow" target="_blank">Python application</a>:</p><ul class=""><li id="c4af" class="oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz qw qx qy bk">Use the IMDB dataset reviews for a semantic search application</li><li id="516e" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk">Learn to use Pinecone Python SDK</li><li id="083c" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk">Create an index of vector embeddings</li><li id="3e33" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk">Upsert vector embeddings</li><li id="57b6" class="oe of gu og b hs qz oi oj hv ra ol om on rb op oq or rc ot ou ov rd ox oy oz qw qx qy bk">Search or query against index for semantic similarity</li></ul><p id="3327" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">To run either example, you’ll need an account on Pinecone and an API key. Those hoping to get a glimpse at the <a class="af pa" href="https://docs.pinecone.io/docs/overview" rel="noopener ugc nofollow" target="_blank">Pinecone SDK and API</a> documentation for vector database and vector embeddings’ CRUD operations won’t be disappointed.</p><figure class="pj pk pl pm pn po pg ph paragraph-image"><div role="button" tabindex="0" class="pp pq fj pr bh ps"><div class="pg ph pi"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*E-7CyvvBpXfPnDPf 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*E-7CyvvBpXfPnDPf 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*E-7CyvvBpXfPnDPf 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*E-7CyvvBpXfPnDPf 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*E-7CyvvBpXfPnDPf 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*E-7CyvvBpXfPnDPf 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*E-7CyvvBpXfPnDPf 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*E-7CyvvBpXfPnDPf 640w, https://miro.medium.com/v2/resize:fit:720/0*E-7CyvvBpXfPnDPf 720w, https://miro.medium.com/v2/resize:fit:750/0*E-7CyvvBpXfPnDPf 750w, https://miro.medium.com/v2/resize:fit:786/0*E-7CyvvBpXfPnDPf 786w, https://miro.medium.com/v2/resize:fit:828/0*E-7CyvvBpXfPnDPf 828w, https://miro.medium.com/v2/resize:fit:1100/0*E-7CyvvBpXfPnDPf 1100w, https://miro.medium.com/v2/resize:fit:1400/0*E-7CyvvBpXfPnDPf 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bh mp pt c" width="700" height="219" loading="lazy" role="presentation"/></picture></div></div><figcaption class="pu ff pv pg ph pw px bf b bg z du"><strong class="bf nk">Figure 5:</strong><a class="af pa" href="https://github.com/dmatrix/genai-cookbook/tree/main/embeddings-and-vectordbs#readme" rel="noopener ugc nofollow" target="_blank"><strong class="bf nk"> </strong>Examples</a> of semantic search with Pinecone vector database</figcaption></figure><h1 id="4c6f" class="ni nj gu bf nk nl nm hu nn no np hx nq nr ns nt nu nv nw nx ny nz oa ob oc od bk">Summary</h1><p id="9d1b" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">In summary, vector embeddings are numerical representations of data that capture semantic meaning. Embeddings can be created for myriad data types: text, audio, image, video, and time.</p><p id="c6d2" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Today, embeddings matter because they are crucial for building generative AI applications, serving as the foundational building blocks. Embeddings are created using machine learning models and have diverse applications such as semantic searches, recommendation systems, anomaly detection, image search, speech recognition, content moderation, spam filtering, conversational agents, and retrieval augmentation generation.</p><p id="5c78" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Through a simple example of semantic search, using embeddings with a vector database like Pinecone, you gained the gist and intuition for vector embeddings.</p><p id="061f" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">Overall, it’s fair to conclude that vector embeddings, along with supported scalable vector databases, will continue to chart a shining and successful path for Generative AI applications, especially for sophisticated multi-modal semantic search engines and retrieval augmented generation systems.</p><h1 id="e8a5" class="ni nj gu bf nk nl nm hu nn no np hx nq nr ns nt nu nv nw nx ny nz oa ob oc od bk">References and Resources</h1><p id="6cbd" class="pw-post-body-paragraph oe of gu og b hs oh oi oj hv ok ol om on oo op oq or os ot ou ov ow ox oy oz gn bk">[1] <a class="af pa" href="https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" rel="noopener ugc nofollow" target="_blank">https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf</a></p><p id="2893" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[2] <a class="af pa" href="https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/" rel="noopener ugc nofollow" target="_blank">https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/</a></p><p id="c8c7" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[3] <a class="af pa" href="https://vectordatabase.substack.com/p/vector-embeddings-101-the-new-building" rel="noopener ugc nofollow" target="_blank">https://vectordatabase.substack.com/p/vector-embeddings-101-the-new-building</a></p><p id="c988" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[4] <a class="af pa" href="https://www.pinecone.io/learn/vector-embeddings-for-developers/" rel="noopener ugc nofollow" target="_blank">https://www.pinecone.io/learn/vector-embeddings-for-developers/</a></p><p id="1aaa" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[5] <a class="af pa" href="https://a16z.com/emerging-architectures-for-llm-applications/" rel="noopener ugc nofollow" target="_blank">https://a16z.com/emerging-architectures-for-llm-applications/</a></p><p id="e1a0" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[6] <a class="af pa" href="https://datasciencedojo.com/blog/vector-embeddings-generative-ai/" rel="noopener ugc nofollow" target="_blank">https://datasciencedojo.com/blog/vector-embeddings-generative-ai/</a></p><p id="eaa3" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[7] <a class="af pa" href="https://causewriter.ai/courses/ai-explainers/lessons/vector-embedding/" rel="noopener ugc nofollow" target="_blank">https://causewriter.ai/courses/ai-explainers/lessons/vector-embedding/</a></p><p id="f2b2" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[8] <a class="af pa" href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Cosine_similarity</a></p><p id="2d34" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[9] <a class="af pa" href="https://www.learndatasci.com/glossary/cosine-similarity/" rel="noopener ugc nofollow" target="_blank">https://www.learndatasci.com/glossary/cosine-similarity/</a></p><p id="86cf" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[10] <a class="af pa" href="https://docs.pinecone.io/page/examples" rel="noopener ugc nofollow" target="_blank">https://docs.pinecone.io/page/examples</a></p><p id="8248" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[11] <a class="af pa" href="https://realpython.com/chromadb-vector-database/" rel="noopener ugc nofollow" target="_blank">https://realpython.com/chromadb-vector-database/</a></p><p id="4316" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[12] <a class="af pa" href="https://causewriter.ai/courses/ai-explainers/lessons/vector-embedding/" rel="noopener ugc nofollow" target="_blank">https://causewriter.ai/courses/ai-explainers/lessons/vector-embedding/</a></p><p id="c704" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[13] <a class="af pa" href="https://vectordatabase.substack.com/p/vector-embeddings-101-the-new-building" rel="noopener ugc nofollow" target="_blank">https://vectordatabase.substack.com/p/vector-embeddings-101-the-new-building</a></p><p id="9236" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[14] <a class="af pa" href="https://openai.com/research/clip" rel="noopener ugc nofollow" target="_blank">https://openai.com/research/clip</a></p><p id="f55d" class="pw-post-body-paragraph oe of gu og b hs pb oi oj hv pc ol om on pd op oq or pe ot ou ov pf ox oy oz gn bk">[15] <a class="af pa" href="https://towardsdatascience.com/clip-model-and-the-importance-of-multimodal-embeddings-1c8f6b13bf72" rel="noopener" target="_blank">https://towardsdatascience.com/clip-model-and-the-importance-of-multimodal-embeddings-1c8f6b13bf72</a></p></div></div></div></div></section></div></div></article></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="re rf ab jm"><div class="rg ab"><a class="rh ay am ao" href="https://medium.com/tag/vector-embeddigns?source=post_page-----ffde295c3558---------------vector_embeddigns-----------------" rel="noopener follow"><div class="ri fj cx rj ge rk rl bf b bg z bk rm">Vector Embeddigns</div></a></div><div class="rg ab"><a class="rh ay am ao" href="https://medium.com/tag/vector-databases?source=post_page-----ffde295c3558---------------vector_databases-----------------" rel="noopener follow"><div class="ri fj cx rj ge rk rl bf b bg z bk rm">Vector Databases</div></a></div><div class="rg ab"><a class="rh ay am ao" href="https://medium.com/tag/generative-ai?source=post_page-----ffde295c3558---------------generative_ai-----------------" rel="noopener follow"><div class="ri fj cx rj ge rk rl bf b bg z bk rm">Generative Ai</div></a></div><div class="rg ab"><a class="rh ay am ao" href="https://medium.com/tag/llms?source=post_page-----ffde295c3558---------------llms-----------------" rel="noopener follow"><div class="ri fj cx rj ge rk rl bf b bg z bk rm">Llms</div></a></div><div class="rg ab"><a class="rh ay am ao" href="https://medium.com/tag/semantic-searches?source=post_page-----ffde295c3558---------------semantic_searches-----------------" rel="noopener follow"><div class="ri fj cx rj ge rk rl bf b bg z bk rm">Semantic Searches</div></a></div></div></div></div><div class="l"></div><footer class="rn ro rp rq rr rs rt ru rv ab q rw iw c"><div class="l ae"><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="ab cp rx"><div class="ab q lh"><div class="ry l"><span class="l rz sa sb e d"><div class="ab q lh li"><div class="pw-multi-vote-icon fj jq lj lk ll"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fai-advances%2Fffde295c3558&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;user=Jules+S.+Damji&amp;userId=603ab1741c22&amp;source=-----ffde295c3558---------------------clap_footer-----------" rel="noopener follow"><div><div class="bm" aria-hidden="false"><div class="lm ao ln lo lp lq am lr ls lt ll"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="bf b dv z du"><span class="mb">--</span></p></div></div></span><span class="l h g f sc sd"><div class="ab q lh li"><div class="pw-multi-vote-icon fj jq lj lk ll"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fai-advances%2Fffde295c3558&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;user=Jules+S.+Damji&amp;userId=603ab1741c22&amp;source=-----ffde295c3558---------------------clap_footer-----------" rel="noopener follow"><div><div class="bm" aria-hidden="false"><div class="lm ao ln lo lp lq am lr ls lt ll"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lu lv lw lx ly lz ma"><p class="bf b dv z du"><span class="mb">--</span></p></div></div></span></div><div class="bq ab"><div><div class="bm" aria-hidden="false"><button class="ao lm mc md ab q fk me mf" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="mg"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg></button></div></div></div></div><div class="ab q"><div class="se l jj"><div><div class="bm" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fffde295c3558&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;source=--------------------------bookmark_footer-----------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="du mi" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="se l jj"><div class="bm" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bm" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af fk ah ai aj ak al mq an ao ap ex mr ms mf mt"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="sf sg sh si sj l bx"><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="cl ab sk cp"><div class="ab im"><a href="https://medium.com/@2twitme?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><div class="l sl sm by sn iq"><div class="l fj"><img alt="Jules S. Damji" class="l fd by so sp cx" src="https://miro.medium.com/v2/resize:fill:144:144/0*hIS9LgEB75e1xfzz.jpeg" width="72" height="72" loading="lazy"/><div class="ir by l so sp fs n is ft"></div></div></div></a><a href="https://ai.gopubby.com/?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><div class="sq ab fj"><div><div class="bm" aria-hidden="false"><div class="l sr ss by sn iw"><div class="l fj"><img alt="AI Advances" class="l fd by bz ca cx" src="https://miro.medium.com/v2/resize:fill:64:64/1*R8zEd59FDf0l8Re94ImV0Q.png" width="32" height="32" loading="lazy"/><div class="ir by l bz ca fs n is ft"></div></div></div></div></div></div></a></div><div class="j i d"><div class="ab"><span><a class="bf b bg z ep ri eq er es et eu ev ew ex ey ez fa au fb fc fd bm fe ff" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F603ab1741c22&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;user=Jules+S.+Damji&amp;userId=603ab1741c22&amp;source=post_page-603ab1741c22----ffde295c3558---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="dt l"><div><div><div class="bm" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F90af6f137475&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;newsletterV3=603ab1741c22&amp;newsletterV3Id=90af6f137475&amp;user=Jules+S.+Damji&amp;userId=603ab1741c22&amp;source=-----ffde295c3558---------------------subscribe_user-----------" rel="noopener follow"><button class="bf b bg z su am sv sw sx sy sz ta tb tc ew ex ey ez fa fb fc fd bm fe ff" aria-label="Subscribe"><svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none" viewBox="0 0 38 38" class="st ss sr"><rect width="0.5" height="6.5" x="26.25" y="9.25" rx="0.25"></rect><rect width="0.5" height="6.5" x="29.75" y="12.25" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5 19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ab cn cp"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" href="https://medium.com/@2twitme?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><h2 class="pw-author-name bf td te tf tg bk"><span class="gn ka">Written by <!-- -->Jules S. Damji</span></h2></a></div><div class="rg ab"><div class="l jj"><span class="pw-follower-count bf b bg z bk"><a class="af ag ah ai aj ak al am an ao ap aq ar jc" href="https://medium.com/@2twitme/followers?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow">427 Followers</a></span></div><div class="bf b bg z jr js jt ab jv jw jx jy du jp"><span class="jd l" aria-hidden="true"><span class="bf b bg z du">·</span></span><span class="l jj">Writer for </span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jc ab q" href="https://ai.gopubby.com/?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><p class="bf b bg z jr js jt ju jv jw jx jy bk">AI Advances</p></a></div></div></div></div><div class="th l"><p class="bf b bg z bk"><span class="gn">Developer at heart; Advocate by nature | Communicator by choice | Avid Arsenal Fan| Love Reading, Writing, APIs, Coding | All Tweets are Mine</span></p></div></div><div class="h k"><div class="ab"><span><a class="bf b bg z ep ri eq er es et eu ev ew ex ey ez fa au fb fc fd bm fe ff" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F603ab1741c22&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;user=Jules+S.+Damji&amp;userId=603ab1741c22&amp;source=post_page-603ab1741c22----ffde295c3558---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="dt l"><div><div><div class="bm" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F90af6f137475&amp;operation=register&amp;redirect=https%3A%2F%2Fai.gopubby.com%2Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558&amp;newsletterV3=603ab1741c22&amp;newsletterV3Id=90af6f137475&amp;user=Jules+S.+Damji&amp;userId=603ab1741c22&amp;source=-----ffde295c3558---------------------subscribe_user-----------" rel="noopener follow"><button class="bf b bg z su am sv sw sx sy sz ta tb tc ew ex ey ez fa fb fc fd bm fe ff" aria-label="Subscribe"><svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none" viewBox="0 0 38 38" class="st ss sr"><rect width="0.5" height="6.5" x="26.25" y="9.25" rx="0.25"></rect><rect width="0.5" height="6.5" x="29.75" y="12.25" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5 19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ti bh tj tk tl tm tn to"></div></div></div><div class="h k j"><div class="ti bh tj tp"></div><div class="ab cb"><div class="ci bh fz ga gb gc"><div class="tq ab lh jm"><div class="tr ts l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><p class="bf b dv z du">Help</p></a></div><div class="tr ts l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><p class="bf b dv z du">Status</p></a></div><div class="tr ts l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1&amp;source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><p class="bf b dv z du">About</p></a></div><div class="tr ts l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><p class="bf b dv z du">Careers</p></a></div><div class="tr ts l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="pressinquiries@medium.com?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><p class="bf b dv z du">Press</p></a></div><div class="tr ts l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><p class="bf b dv z du">Blog</p></a></div><div class="tr ts l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><p class="bf b dv z du">Privacy</p></a></div><div class="tr ts l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><p class="bf b dv z du">Terms</p></a></div><div class="tr ts l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><p class="bf b dv z du">Text to speech</p></a></div><div class="tr l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/business?source=post_page-----ffde295c3558--------------------------------" rel="noopener follow"><p class="bf b dv z du">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20240906-083156-e8cf1d3448"</script><script>window.__GRAPHQL_URI__ = "https://ai.gopubby.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-ffde295c3558","user-603ab1741c22","collection-3fe99b2acc4"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"lohpSummerUpsellEnabled":false,"logoUpdatePhase3Enabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":true,"routingEntity":{"type":"COLLECTION","id":"3fe99b2acc4","explicit":true},"viewerIsBot":false},"debug":{"requestId":"7ed3d308-edc4-4f12-8480-45eab7ce3b92","hybridDevServices":[],"originalSpanCarrier":{"traceparent":"00-d2ef4a5aa239bc9b7407efaf16fc3ddf-bc177c81a03b8651-01"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fai.gopubby.com\u002Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558","host":"ai.gopubby.com","hostname":"ai.gopubby.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"partnerProgram":{"selectedCountryCode":null},"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20240906-083156-e8cf1d3448","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20240906-083156-e8cf1d3448","commit":"e8cf1d34485e905f8219bb5466c319d626d1d15a"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"7*V1_7XP4snlmqrc_0Njontw.png","height":110,"width":500},"postLogo":{"imageId":"bd978bb536350a710e8efb012513429cabdc4c28700604261aeda246d0f980b7","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyV2":"e8a5e126-792b-4ee6-8fba-d574c1b02fc5","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyV2":"3815d7d6-b8ca-4224-9b8c-182f9047866e","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyOneYearFree":"e6c0637a-2bad-4171-ab4f-3c268633d83c","monthly25PercentOffFirstYear":"235ecc62-0cdb-49ae-9378-726cd21c504b","monthly20PercentOffFirstYear":"ba518864-9c13-4a99-91ca-411bf0cac756","monthly15PercentOffFirstYear":"594c029b-9f89-43d5-88f8-8173af4e070e","monthly10PercentOffFirstYear":"c6c7bc9a-40f2-4b51-8126-e28511d5bdb0","monthlyForStudents":"629ebe51-da7d-41fd-8293-34cd2f2030a8","yearlyOneYearFree":"78ba7be9-0d9f-4ece-aa3e-b54b826f2bf1","yearly25PercentOffFirstYear":"2dbb010d-bb8f-4eeb-ad5c-a08509f42d34","yearly20PercentOffFirstYear":"47565488-435b-47f8-bf93-40d5fbe0ebc8","yearly15PercentOffFirstYear":"8259809b-0881-47d9-acf7-6c001c7f720f","yearly10PercentOffFirstYear":"9dd694fb-96e1-472c-8d9e-3c868d5c1506","yearlyForStudents":"e29345ef-ab1c-4234-95c5-70e50fe6bc23","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"collectionByDomainOrSlug({\"domainOrSlug\":\"ai.gopubby.com\"})":{"__ref":"Collection:3fe99b2acc4"},"postResult({\"id\":\"ffde295c3558\"})":{"__ref":"Post:ffde295c3558"}},"ImageMetadata:1*8xkFb5PlJ9-jlzImmpZsGg.png":{"__typename":"ImageMetadata","id":"1*8xkFb5PlJ9-jlzImmpZsGg.png"},"Collection:3fe99b2acc4":{"__typename":"Collection","id":"3fe99b2acc4","favicon":{"__ref":"ImageMetadata:1*8xkFb5PlJ9-jlzImmpZsGg.png"},"customStyleSheet":null,"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFECF3FF","point":0},{"__typename":"ColorPoint","color":"#FFE8F2FF","point":0.1},{"__typename":"ColorPoint","color":"#FFE4F0FF","point":0.2},{"__typename":"ColorPoint","color":"#FFE1EFFF","point":0.3},{"__typename":"ColorPoint","color":"#FFDDEDFF","point":0.4},{"__typename":"ColorPoint","color":"#FFD9EBFF","point":0.5},{"__typename":"ColorPoint","color":"#FFD5EAFF","point":0.6},{"__typename":"ColorPoint","color":"#FFD1E8FF","point":0.7},{"__typename":"ColorPoint","color":"#FFCDE6FF","point":0.8},{"__typename":"ColorPoint","color":"#FFC9E5FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC5E3FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF6288C1","point":0},{"__typename":"ColorPoint","color":"#FF5C7EB1","point":0.1},{"__typename":"ColorPoint","color":"#FF5775A2","point":0.2},{"__typename":"ColorPoint","color":"#FF506B93","point":0.3},{"__typename":"ColorPoint","color":"#FF4A6183","point":0.4},{"__typename":"ColorPoint","color":"#FF435674","point":0.5},{"__typename":"ColorPoint","color":"#FF3B4B64","point":0.6},{"__typename":"ColorPoint","color":"#FF334054","point":0.7},{"__typename":"ColorPoint","color":"#FF2A3444","point":0.8},{"__typename":"ColorPoint","color":"#FF202834","point":0.9},{"__typename":"ColorPoint","color":"#FF151B23","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF264C82","colorPoints":[{"__typename":"ColorPoint","color":"#FF264C82","point":0},{"__typename":"ColorPoint","color":"#FF416294","point":0.1},{"__typename":"ColorPoint","color":"#FF5877A4","point":0.2},{"__typename":"ColorPoint","color":"#FF6F8AB3","point":0.3},{"__typename":"ColorPoint","color":"#FF849CC2","point":0.4},{"__typename":"ColorPoint","color":"#FF99AECF","point":0.5},{"__typename":"ColorPoint","color":"#FFADBFDC","point":0.6},{"__typename":"ColorPoint","color":"#FFC1D0E9","point":0.7},{"__typename":"ColorPoint","color":"#FFD4E0F5","point":0.8},{"__typename":"ColorPoint","color":"#FFE7F0FF","point":0.9},{"__typename":"ColorPoint","color":"#FFFAFFFF","point":1}]}},"googleAnalyticsId":null,"editors":[{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:4c5bf5f200c3"}}],"name":"AI Advances","avatar":{"__ref":"ImageMetadata:1*R8zEd59FDf0l8Re94ImV0Q.png"},"domain":"ai.gopubby.com","slug":"ai-advances","description":"Democratizing access to artificial intelligence","subscriberCount":4157,"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:3fe99b2acc4-viewerId:lo_d46a31de4e77"},"twitterUsername":"AIAdvances","facebookPageId":null,"logo":{"__ref":"ImageMetadata:"}},"User:4c5bf5f200c3":{"__typename":"User","id":"4c5bf5f200c3"},"ImageMetadata:1*R8zEd59FDf0l8Re94ImV0Q.png":{"__typename":"ImageMetadata","id":"1*R8zEd59FDf0l8Re94ImV0Q.png"},"LinkedAccounts:603ab1741c22":{"__typename":"LinkedAccounts","mastodon":null,"id":"603ab1741c22"},"UserViewerEdge:userId:603ab1741c22-viewerId:lo_d46a31de4e77":{"__typename":"UserViewerEdge","id":"userId:603ab1741c22-viewerId:lo_d46a31de4e77","isFollowing":false,"isUser":false,"isMuting":false},"NewsletterV3:90af6f137475":{"__typename":"NewsletterV3","id":"90af6f137475","type":"NEWSLETTER_TYPE_AUTHOR","slug":"603ab1741c22","name":"603ab1741c22","collection":null,"user":{"__ref":"User:603ab1741c22"}},"User:603ab1741c22":{"__typename":"User","id":"603ab1741c22","name":"Jules S. Damji","username":"2twitme","newsletterV3":{"__ref":"NewsletterV3:90af6f137475"},"linkedAccounts":{"__ref":"LinkedAccounts:603ab1741c22"},"isSuspended":false,"imageId":"0*hIS9LgEB75e1xfzz.jpeg","mediumMemberAt":1717257332939,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":427},"customDomainState":null,"hasSubdomain":false,"bio":"Developer at heart; Advocate by nature | Communicator by choice | Avid Arsenal Fan| Love Reading, Writing, APIs, Coding | All Tweets are Mine","isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:603ab1741c22-viewerId:lo_d46a31de4e77"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"twitterScreenName":"2twitme","membership":{"__ref":"Membership:bc60a724-4f2e-4a07-bc06-883a0f1c013e"}},"Paragraph:0164f3af9593_0":{"__typename":"Paragraph","id":"0164f3af9593_0","name":"a83e","type":"H3","href":null,"layout":null,"metadata":null,"text":"An Intuitive 101 Guide to Vector Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_1":{"__typename":"Paragraph","id":"0164f3af9593_1","name":"28bc","type":"H4","href":null,"layout":null,"metadata":null,"text":"Vector embeddings matter as fundamental building blocks for Generative AI","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_2":{"__typename":"Paragraph","id":"0164f3af9593_2","name":"8835","type":"H3","href":null,"layout":null,"metadata":null,"text":"Introduction","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_3":{"__typename":"Paragraph","id":"0164f3af9593_3","name":"4e61","type":"P","href":null,"layout":null,"metadata":null,"text":"Embeddings, particularly text or word embeddings, are not novel today. Bengio et al. originally coined the term ‘word embeddings’ in 2003, training them in a Neural Probabilistic Language Model along with the model’s parameters. [1] Since then, their representation, algorithms, and models to compute embeddings are predominantly used in natural language processing (NLP) tasks.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":230,"end":231,"href":"https:\u002F\u002Fwww.jmlr.org\u002Fpapers\u002Fvolume3\u002Fbengio03a\u002Fbengio03a.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_4":{"__typename":"Paragraph","id":"0164f3af9593_4","name":"dddf","type":"P","href":null,"layout":null,"metadata":null,"text":"Originally confined to use cases for semantic textual searches, rather than traditional string or keyword pattern matching, embeddings are now used in other semantic search engines for images, audio, and videos. In more recent times, they have gained immense prominence and are widely utilized in generative AI applications.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_5":{"__typename":"Paragraph","id":"0164f3af9593_5","name":"776e","type":"P","href":null,"layout":null,"metadata":null,"text":"Conceptually, Kevin Henner describes vectors as “an embedding [in vector] space or latent space, as a manifold in which similar items are positioned closer to one another than less similar items. In this case, sentences [or data objects] that are semantically similar should have similar embedded vectors and thus be closer together in space.” [2]","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":345,"end":346,"href":"https:\u002F\u002Fstackoverflow.blog\u002F2023\u002F11\u002F09\u002Fan-intuitive-introduction-to-text-embeddings\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_6":{"__typename":"Paragraph","id":"0164f3af9593_6","name":"59a0","type":"P","href":null,"layout":null,"metadata":null,"text":"Similarly, Nathan Crone defines a vector embedding simply as “… a vector created as the numerical representation of typically non-numerical data objects. Embeddings capture the inherent properties and relationships of the original data in a condensed [or dense] format and are often used in machine learning use cases,” [3] as depicted in Figure 1.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":321,"end":322,"href":"https:\u002F\u002Fvectordatabase.substack.com\u002Fp\u002Fvector-embeddings-101-the-new-building","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":339,"end":347,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*jOGKVlYLxPTmOLal":{"__typename":"ImageMetadata","id":"0*jOGKVlYLxPTmOLal","originalHeight":765,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:0164f3af9593_7":{"__typename":"Paragraph","id":"0164f3af9593_7","name":"ff92","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*jOGKVlYLxPTmOLal"},"text":"Figure 1: Documents transformed into embeddings and projected into vector space [4]","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":81,"end":82,"href":"https:\u002F\u002Fdatasciencedojo.com\u002Fblog\u002Fvector-embeddings-generative-ai\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_8":{"__typename":"Paragraph","id":"0164f3af9593_8","name":"3627","type":"P","href":null,"layout":null,"metadata":null,"text":"In essence, we can describe embeddings as high-dimensional cardinal data reduced or condensed into two or three lower dimensional latent vector spaces. As vectors projected into a latent space, computers can then perform fast mathematical operations such as measuring distances, calculating similarities, and performing transformations on an array or a matrix of vectors.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_9":{"__typename":"Paragraph","id":"0164f3af9593_9","name":"5d91","type":"P","href":null,"layout":null,"metadata":null,"text":"Python’s numpy and spacy libraries offer efficient vector operations and transformations, particularly for NLP tasks, such as computing the distance, evaluating proximity of vectors close to each other, or employing trained models to generate embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":9,"end":14,"href":"https:\u002F\u002Fnumpy.org\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":19,"end":24,"href":"https:\u002F\u002Fspacy.io\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_10":{"__typename":"Paragraph","id":"0164f3af9593_10","name":"02ef","type":"P","href":null,"layout":null,"metadata":null,"text":"In this article, we explore the fundamental concept of vector embeddings, why they matter, what they are, and what they are used for. We won’t delve or dive into how embedding models are trained.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_11":{"__typename":"Paragraph","id":"0164f3af9593_11","name":"74f6","type":"H3","href":null,"layout":null,"metadata":null,"text":"Why embeddings matter","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_12":{"__typename":"Paragraph","id":"0164f3af9593_12","name":"2944","type":"P","href":null,"layout":null,"metadata":null,"text":"Embeddings matter because they capture the essence and meaning of data in a numerical form. As such computers can deal efficiently with numerical representation of any structured or unstructured data. Generated as data’s numerical vectors and projected into a latent multi-dimensional space, they capture and preserve data’s semantic meaning. Their essence, then, can be persisted in purpose-built data stores called vector databases.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*VGQaay1U0-9NfA2D":{"__typename":"ImageMetadata","id":"0*VGQaay1U0-9NfA2D","originalHeight":1068,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:0164f3af9593_13":{"__typename":"Paragraph","id":"0164f3af9593_13","name":"7c8e","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*VGQaay1U0-9NfA2D"},"text":"Figure 2: Courtesy of DALL-E 3 rendering a vector database with myriad data embeddings","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":8,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_14":{"__typename":"Paragraph","id":"0164f3af9593_14","name":"6adb","type":"P","href":null,"layout":null,"metadata":null,"text":"Embeddings matter because the recent emergence of scalable purpose-built vector databases serve scalable vector-based computational needs for tasks common to NLP and generative AI.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_15":{"__typename":"Paragraph","id":"0164f3af9593_15","name":"6d50","type":"P","href":null,"layout":null,"metadata":null,"text":"In a post Emerging Architectures for LLM Applications, based on conversations with AI startup founders and engineers, Andreessen Horowitz report that vector databases play a pivotal role as part of the preprocessing pipeline for emerging generative AI application stack, allowing for efficient storage, retrieval, comparison, searches, and computation of vector embeddings at scale. [5]","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":10,"end":53,"href":"https:\u002F\u002Fa16z.com\u002Femerging-architectures-for-llm-applications\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":384,"end":385,"href":"https:\u002F\u002Fa16z.com\u002Femerging-architectures-for-llm-applications\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_16":{"__typename":"Paragraph","id":"0164f3af9593_16","name":"710b","type":"P","href":null,"layout":null,"metadata":null,"text":"Asked in simple terms, what form and format do these vector embeddings take? Let’s look at a simple example to get an intuition.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_17":{"__typename":"Paragraph","id":"0164f3af9593_17","name":"cc71","type":"H3","href":null,"layout":null,"metadata":null,"text":"What are vectors embedding","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_18":{"__typename":"Paragraph","id":"0164f3af9593_18","name":"fc6c","type":"P","href":null,"layout":null,"metadata":null,"text":"From above, it follows that a vector embedding is a single dimensional or multi-dimensional array of sequence of numbers, where each number may correspond to data’s semantic meaning in relation to the other numbers in the sequence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_19":{"__typename":"Paragraph","id":"0164f3af9593_19","name":"1b2a","type":"P","href":null,"layout":null,"metadata":null,"text":"For example, assume the vector_1 = [0.5, 1.75, -2, …, 0.9] could capture the semantic meaning of “The cat sat on a cushy mat.” Another vector, vector_2 = [0.5, 1.65, -1, …, 0.9], could capture the meaning of “The cat stretched and laid down on a furry mat.”","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_20":{"__typename":"Paragraph","id":"0164f3af9593_20","name":"ea1c","type":"P","href":null,"layout":null,"metadata":null,"text":"The above two vector embeddings are deemed relatively similar if they possess semantic similarity. In the above case, this semantic similarity of two vectors is expressed as the shortest distance between them when they are projected in a vector space. It follows that we can confidently assert that similar vector embeddings will congregate into clusters, and, therefore, we can fetch all its N nearest neighbors within a cluster of similar vector embeddings. See Figure 3.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":464,"end":472,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*jL-xIBkXNqlvF1UD":{"__typename":"ImageMetadata","id":"0*jL-xIBkXNqlvF1UD","originalHeight":692,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:0164f3af9593_21":{"__typename":"Paragraph","id":"0164f3af9593_21","name":"16aa","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*jL-xIBkXNqlvF1UD"},"text":"Figure 3. Similar vector embeddings projected in 2D space clustered together [6]","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":78,"end":80,"href":"https:\u002F\u002Fdatasciencedojo.com\u002Fblog\u002Fvector-embeddings-generative-ai\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_22":{"__typename":"Paragraph","id":"0164f3af9593_22","name":"6f4a","type":"P","href":null,"layout":null,"metadata":null,"text":"To compute the shortest distance between two projected vectors, cosine similarity is a common method; another one is Euclidean distance. Cosine similarity measures the cosine of the angle between two vectors and ranges from -1 to 1, where 1 means the vectors are identical, -1 means they are opposites, and 0 means they are orthogonal (i.e., unrelated). [7]","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":137,"end":154,"href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCosine_similarity)","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":355,"end":356,"href":"https:\u002F\u002Fcausewriter.ai\u002Fcourses\u002Fai-explainers\u002Flessons\u002Fvector-embedding\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*mdpXDa066Gez0En7":{"__typename":"ImageMetadata","id":"0*mdpXDa066Gez0En7","originalHeight":510,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:0164f3af9593_23":{"__typename":"Paragraph","id":"0164f3af9593_23","name":"0253","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*mdpXDa066Gez0En7"},"text":"Figure 4: Cosine similarity is the smallest angle and shortest distance between two vectors [8,9]","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":93,"end":94,"href":"https:\u002F\u002Fwww.learndatasci.com\u002Fglossary\u002Fcosine-similarity\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":95,"end":96,"href":"https:\u002F\u002Fwww.learndatasci.com\u002Fglossary\u002Fcosine-similarity\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_24":{"__typename":"Paragraph","id":"0164f3af9593_24","name":"d5c8","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s take the above simple example of the “cat on the mat” a bit further and compute its cosine similarity to ascertain if they are semantically similar. We will use the numpy library.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_25":{"__typename":"Paragraph","id":"0164f3af9593_25","name":"1898","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import numpy as np\n\nv1 = np.array([0.5, 1.75, -2, ..., 0.9])  # Replace '...' with the remaining elements\nv2 = np.array([0.5, 1.65, -1, ..., 0.9])  # Replace '...' with the remaining elements\n\n# Compute the length of each vector\nlength_v1 = np.linalg.norm(v1)\nlength_v2 = np.linalg.norm(v2)\n\nprint(\"Length of v1:\", length_v1)  # Length of v1: 2.85\nprint(\"Length of v2:\", length_v2)  # Length of v2: 2.17\n\n# Compute cosine similarity\ncos_sim = np.dot(v1, v2) \u002F (np.linalg.norm(v1) * np.linalg.norm(v2))\n\nprint(\"Cosine similarity:\", cos_sim) # Cosine similarity: 0.954","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_26":{"__typename":"Paragraph","id":"0164f3af9593_26","name":"f53b","type":"P","href":null,"layout":null,"metadata":null,"text":"Since cosine similarity of 0.954 =~ 1, they are similar in semantics. Another way to compute cosine similarity using an embedding model encoder:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_27":{"__typename":"Paragraph","id":"0164f3af9593_27","name":"8603","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('bert-base-nli-mean-tokens')\n\n#input sentences\nsentences = ['The cat sat on a mushy mat',\n             'The cat stretched and laid down on a furry mat']\n\n#encode sentences\nembeddings = model.encode(sentences)\n\n#output embeddings\nfor phrase, embedding in zip(sentences, embeddings):\n    print(\"Phrase:\", phrase)\n    print(\"Embedding shape:\", embedding.shape) \n    print(\"Embedding:\", embedding[0:5])\nprint(\"--\" * 40)\n\n# compute cosine similarity\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncs = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\nprint (f\"Cosine similarity: {cs:.4f}\")\n\n#ouput from above\nPhrase: The cat sat on a mushy mat\nEmbedding shape: (768,)\nEmbedding: [ 0.00477061  0.43979567 -0.01233868 -0.3416704  -0.24160706]\nPhrase: The cat stretched and laid down on a furry mat\nEmbedding shape: (768,)\nEmbedding: [ 0.10522226 -0.06775486  0.09200469 -0.78158903 -0.26045752]\n------------------------------------------------------------------------\nCosine similarity: 0.9192","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_28":{"__typename":"Paragraph","id":"0164f3af9593_28","name":"3a9e","type":"P","href":null,"layout":null,"metadata":null,"text":"Vector embeddings are not restricted only to textual data. Other forms of data can also be converted to vector embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_29":{"__typename":"Paragraph","id":"0164f3af9593_29","name":"6ce6","type":"H3","href":null,"layout":null,"metadata":null,"text":"Types of vector embeddings: text, video, image, audio, and time","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_30":{"__typename":"Paragraph","id":"0164f3af9593_30","name":"2482","type":"P","href":null,"layout":null,"metadata":null,"text":"In the digital domain, data exists in myriad formats. And to process this data, to make sense of data, or to use data to train a model for a specific task, we need vector embeddings for each respective data type. So multi-model vector embeddings can be created for various types of data, including text, video, image, audio, and time. Today, each type of vector embedding serves a specific use case in generative AI applications. Here are a few examples:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_31":{"__typename":"Paragraph","id":"0164f3af9593_31","name":"4dda","type":"H4","href":null,"layout":null,"metadata":null,"text":"Text Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_32":{"__typename":"Paragraph","id":"0164f3af9593_32","name":"2477","type":"P","href":null,"layout":null,"metadata":null,"text":"Text embeddings represent textual data, such as sentences, documents, or words, as numerical vectors. Since these vectors capture the semantic meaning of the text, they can be used for tasks like semantic search, text classification, and language generation.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_33":{"__typename":"Paragraph","id":"0164f3af9593_33","name":"ce92","type":"H4","href":null,"layout":null,"metadata":null,"text":"Video and Image Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_34":{"__typename":"Paragraph","id":"0164f3af9593_34","name":"d9a2","type":"P","href":null,"layout":null,"metadata":null,"text":"Video embeddings encode video data as numerical vectors. Capturing visual features and temporal information from the video frames, video embeddings are useful for tasks such as video recommendation, video search, and video summarization.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_35":{"__typename":"Paragraph","id":"0164f3af9593_35","name":"d538","type":"P","href":null,"layout":null,"metadata":null,"text":"Similarly, image embeddings capture visual features like shape, texture, and color and are useful for image recognition and comparison.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_36":{"__typename":"Paragraph","id":"0164f3af9593_36","name":"0506","type":"H4","href":null,"layout":null,"metadata":null,"text":"Audio Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_37":{"__typename":"Paragraph","id":"0164f3af9593_37","name":"5362","type":"P","href":null,"layout":null,"metadata":null,"text":"Audio embeddings capture audio data, including speech or music, as numerical vectors, incorporating acoustic features and temporal patterns in the audio. As such, they can be used in tasks, including speech recognition, music recommendation, speech imitation, and audio similarity matching.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_38":{"__typename":"Paragraph","id":"0164f3af9593_38","name":"0b31","type":"H4","href":null,"layout":null,"metadata":null,"text":"Time Embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_39":{"__typename":"Paragraph","id":"0164f3af9593_39","name":"3ec7","type":"P","href":null,"layout":null,"metadata":null,"text":"Time embeddings represent temporal data, such as timestamps or time series. These numerical vectors capture the temporal patterns and relationships in the data. They are useful for tasks like time series forecasting, event detection, and anomaly detection in temporal data.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_40":{"__typename":"Paragraph","id":"0164f3af9593_40","name":"072c","type":"P","href":null,"layout":null,"metadata":null,"text":"How does all this magical transformation work? 🧙‍♀️","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_41":{"__typename":"Paragraph","id":"0164f3af9593_41","name":"4d1e","type":"H3","href":null,"layout":null,"metadata":null,"text":"How vector embeddings are created","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_42":{"__typename":"Paragraph","id":"0164f3af9593_42","name":"d238","type":"P","href":null,"layout":null,"metadata":null,"text":"Vector embeddings are created through machine learning. Initially, a specialized model is trained for specific data types. This model learns to convert diverse training data into numerical vectors. Once trained, the model can generate vector embeddings for your data, taking specific data as input and producing vector embedding as output — and vice versa.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_43":{"__typename":"Paragraph","id":"0164f3af9593_43","name":"79ef","type":"P","href":null,"layout":null,"metadata":null,"text":"While the actual process of training a specific model is beyond the scope of this discussion, plenty of literature describe, at length and in mathematical details, how the embedding models are trained, the respective training data marshaled and employed, and the underlying neural network architecture used.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":94,"end":124,"href":"https:\u002F\u002Flink.springer.com\u002Farticle\u002F10.1007\u002Fs41060-021-00242-8","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_44":{"__typename":"Paragraph","id":"0164f3af9593_44","name":"7f59","type":"P","href":null,"layout":null,"metadata":null,"text":"However, it’s worth noting that some of these models are readily accessible for your use. They encode your data into vector embeddings and vice versa. Several of these multi-modal models have been instrumental in developing advanced NLP and semantic search applications. Notable examples include Google Language Translation, image identification, and classification.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_45":{"__typename":"Paragraph","id":"0164f3af9593_45","name":"8547","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Word2vec","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":8,"href":"https:\u002F\u002Fwww.tensorflow.org\u002Ftext\u002Ftutorials\u002Fword2vec","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_46":{"__typename":"Paragraph","id":"0164f3af9593_46","name":"dcf3","type":"ULI","href":null,"layout":null,"metadata":null,"text":"GloVe","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":5,"href":"https:\u002F\u002Fcodeblockhub.com\u002Fpython\u002Fglove-models-python\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_47":{"__typename":"Paragraph","id":"0164f3af9593_47","name":"9fa7","type":"ULI","href":null,"layout":null,"metadata":null,"text":"FastText","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":8,"href":"https:\u002F\u002Fgithub.com\u002Ffacebookresearch\u002FfastText","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_48":{"__typename":"Paragraph","id":"0164f3af9593_48","name":"5541","type":"ULI","href":null,"layout":null,"metadata":null,"text":"BERT","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":4,"href":"https:\u002F\u002Fblog.research.google\u002F2018\u002F11\u002Fopen-sourcing-bert-state-of-art-pre.html)","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_49":{"__typename":"Paragraph","id":"0164f3af9593_49","name":"0233","type":"ULI","href":null,"layout":null,"metadata":null,"text":"ELMo","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":4,"href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FELMo","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_50":{"__typename":"Paragraph","id":"0164f3af9593_50","name":"824b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"CLIP","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":4,"href":"https:\u002F\u002Fopenai.com\u002Fresearch\u002Fclip","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_51":{"__typename":"Paragraph","id":"0164f3af9593_51","name":"28b7","type":"P","href":null,"layout":null,"metadata":null,"text":"Adding to the collection of embedding models, other AI model vendors such as HuggingFace, Cohere, Databricks, Pinecone, and OpenAI offer embedding models as a service. Additionally, purpose-built and vector-based storage vendors like Pinecone offer scalable and enterprise-grade vector databases for storage and retrieval.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":77,"end":88,"href":"https:\u002F\u002Fhuggingface.co\u002Fmodels?other=embeddings)","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":90,"end":96,"href":"https:\u002F\u002Ftxt.cohere.com\u002Fintroducing-embed-v3\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":98,"end":108,"href":"https:\u002F\u002Fdocs.databricks.com\u002Fen\u002Fgenerative-ai\u002Fcreate-query-vector-search.html","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":110,"end":118,"href":"https:\u002F\u002Fwww.pinecone.io\u002Fmodels\u002F","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":124,"end":130,"href":"https:\u002F\u002Fwww.pinecone.io\u002Flearn\u002Fopenai-embeddings-v3","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":234,"end":242,"href":"https:\u002F\u002Fwww.pinecone.io\u002Fproduct\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_52":{"__typename":"Paragraph","id":"0164f3af9593_52","name":"972b","type":"H3","href":null,"layout":null,"metadata":null,"text":"How vector embeddings are used today","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_53":{"__typename":"Paragraph","id":"0164f3af9593_53","name":"65f9","type":"P","href":null,"layout":null,"metadata":null,"text":"It’s no secret that embeddings matter (as mentioned above) and have become pervasive because of deep learning and large language models (LLMs) technologies. More recently, they’ve become fundamental building blocks in generative AI applications, in which data is preprocessed, represented, computed, stored, sand presented to large language models for generating responses. They are at the core of how data is consumed in these technologies.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_54":{"__typename":"Paragraph","id":"0164f3af9593_54","name":"3064","type":"P","href":null,"layout":null,"metadata":null,"text":"Today, its use cases extends to:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_55":{"__typename":"Paragraph","id":"0164f3af9593_55","name":"dfff","type":"ULI","href":null,"layout":null,"metadata":null,"text":"semantic searches: sophisticated search engines go beyond just keyword or pattern matching; they include other data types — images, audio and video — allowing search across multiple data formats for semantic similarities.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_56":{"__typename":"Paragraph","id":"0164f3af9593_56","name":"b114","type":"ULI","href":null,"layout":null,"metadata":null,"text":"recommendation systems: capture embeddings of articles, products, images, and recommend matching or similar items selected by the users during their perusal of web content.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_57":{"__typename":"Paragraph","id":"0164f3af9593_57","name":"162b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"anomaly detection: create an embedding of a target entity that does not match any existing entities stored in a vector database, indicating the target item as an anomaly.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_58":{"__typename":"Paragraph","id":"0164f3af9593_58","name":"ad47","type":"ULI","href":null,"layout":null,"metadata":null,"text":"image search, retrieval, and classification: image similarity is a common use case in various scenarios, including nefarious surveillance. CLIP models are used for identifying images using natural language descriptions.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":139,"end":143,"href":"https:\u002F\u002Ftowardsdatascience.com\u002Fclip-model-and-the-importance-of-multimodal-embeddings-1c8f6b13bf72","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":43,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_59":{"__typename":"Paragraph","id":"0164f3af9593_59","name":"30d4","type":"ULI","href":null,"layout":null,"metadata":null,"text":"content generation: detect similarity of a social post, including offensive images, to known examples of abuse stored as embeddings in an indexed vector database. CLIP models can identify images and filter harmful content.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":163,"end":167,"href":"https:\u002F\u002Ftowardsdatascience.com\u002Fclip-model-and-the-importance-of-multimodal-embeddings-1c8f6b13bf72","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_60":{"__typename":"Paragraph","id":"0164f3af9593_60","name":"9a67","type":"ULI","href":null,"layout":null,"metadata":null,"text":"spam filtering or classification: classify emails as examples of spam mail.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":32,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_61":{"__typename":"Paragraph","id":"0164f3af9593_61","name":"3d45","type":"ULI","href":null,"layout":null,"metadata":null,"text":"conversational agent: match existing embeddings in an indexed vector database that are semantically close to the users’ messages or queries.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":20,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_62":{"__typename":"Paragraph","id":"0164f3af9593_62","name":"8d1b","type":"ULI","href":null,"layout":null,"metadata":null,"text":"retrieval augmentation generation: use proprietary data, combined with LLMs, for an authoritative generated AI results, with more factual accuracy and less hallucination.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":33,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_63":{"__typename":"Paragraph","id":"0164f3af9593_63","name":"e0cb","type":"P","href":null,"layout":null,"metadata":null,"text":"All in all, vector embeddings are crucial today for the above use cases and are immensely powerful and useful; their applications are at the core of numerous semantic search technologies and generative AI applications. For example, Pinecone tabulates some of the example use cases. [10]","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_64":{"__typename":"Paragraph","id":"0164f3af9593_64","name":"c54c","type":"H3","href":null,"layout":null,"metadata":null,"text":"How to use embeddings: semantic search application using a vector database","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_65":{"__typename":"Paragraph","id":"0164f3af9593_65","name":"0fc0","type":"P","href":null,"layout":null,"metadata":null,"text":"For a quick, getting-started version of how to use vector embeddings for semantic search with a Pinecone vector database, checkout both notebook and Python application:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":136,"end":144,"href":"https:\u002F\u002Fgithub.com\u002Fdmatrix\u002Fgenai-cookbook\u002Fblob\u002Fmain\u002Fembeddings-and-vectordbs\u002F1_pinecone_semantic_search_example.ipynb","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":149,"end":167,"href":"https:\u002F\u002Fgithub.com\u002Fdmatrix\u002Fgenai-cookbook\u002Fblob\u002Fmain\u002Fembeddings-and-vectordbs\u002Fpinecone_semantic_search_example.py","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_66":{"__typename":"Paragraph","id":"0164f3af9593_66","name":"c4af","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Use the IMDB dataset reviews for a semantic search application","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_67":{"__typename":"Paragraph","id":"0164f3af9593_67","name":"516e","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Learn to use Pinecone Python SDK","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_68":{"__typename":"Paragraph","id":"0164f3af9593_68","name":"083c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Create an index of vector embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_69":{"__typename":"Paragraph","id":"0164f3af9593_69","name":"3e33","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Upsert vector embeddings","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_70":{"__typename":"Paragraph","id":"0164f3af9593_70","name":"57b6","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Search or query against index for semantic similarity","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_71":{"__typename":"Paragraph","id":"0164f3af9593_71","name":"3327","type":"P","href":null,"layout":null,"metadata":null,"text":"To run either example, you’ll need an account on Pinecone and an API key. Those hoping to get a glimpse at the Pinecone SDK and API documentation for vector database and vector embeddings’ CRUD operations won’t be disappointed.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":111,"end":131,"href":"https:\u002F\u002Fdocs.pinecone.io\u002Fdocs\u002Foverview","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*E-7CyvvBpXfPnDPf":{"__typename":"ImageMetadata","id":"0*E-7CyvvBpXfPnDPf","originalHeight":500,"originalWidth":1600,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:0164f3af9593_72":{"__typename":"Paragraph","id":"0164f3af9593_72","name":"a453","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*E-7CyvvBpXfPnDPf"},"text":"Figure 5: Examples of semantic search with Pinecone vector database","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":9,"end":18,"href":"https:\u002F\u002Fgithub.com\u002Fdmatrix\u002Fgenai-cookbook\u002Ftree\u002Fmain\u002Fembeddings-and-vectordbs#readme","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_73":{"__typename":"Paragraph","id":"0164f3af9593_73","name":"4c6f","type":"H3","href":null,"layout":null,"metadata":null,"text":"Summary","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_74":{"__typename":"Paragraph","id":"0164f3af9593_74","name":"9d1b","type":"P","href":null,"layout":null,"metadata":null,"text":"In summary, vector embeddings are numerical representations of data that capture semantic meaning. Embeddings can be created for myriad data types: text, audio, image, video, and time.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_75":{"__typename":"Paragraph","id":"0164f3af9593_75","name":"c6d2","type":"P","href":null,"layout":null,"metadata":null,"text":"Today, embeddings matter because they are crucial for building generative AI applications, serving as the foundational building blocks. Embeddings are created using machine learning models and have diverse applications such as semantic searches, recommendation systems, anomaly detection, image search, speech recognition, content moderation, spam filtering, conversational agents, and retrieval augmentation generation.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_76":{"__typename":"Paragraph","id":"0164f3af9593_76","name":"5c78","type":"P","href":null,"layout":null,"metadata":null,"text":"Through a simple example of semantic search, using embeddings with a vector database like Pinecone, you gained the gist and intuition for vector embeddings.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_77":{"__typename":"Paragraph","id":"0164f3af9593_77","name":"061f","type":"P","href":null,"layout":null,"metadata":null,"text":"Overall, it’s fair to conclude that vector embeddings, along with supported scalable vector databases, will continue to chart a shining and successful path for Generative AI applications, especially for sophisticated multi-modal semantic search engines and retrieval augmented generation systems.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_78":{"__typename":"Paragraph","id":"0164f3af9593_78","name":"e8a5","type":"H3","href":null,"layout":null,"metadata":null,"text":"References and Resources","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_79":{"__typename":"Paragraph","id":"0164f3af9593_79","name":"6cbd","type":"P","href":null,"layout":null,"metadata":null,"text":"[1] https:\u002F\u002Fwww.jmlr.org\u002Fpapers\u002Fvolume3\u002Fbengio03a\u002Fbengio03a.pdf","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":4,"end":63,"href":"https:\u002F\u002Fwww.jmlr.org\u002Fpapers\u002Fvolume3\u002Fbengio03a\u002Fbengio03a.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_80":{"__typename":"Paragraph","id":"0164f3af9593_80","name":"2893","type":"P","href":null,"layout":null,"metadata":null,"text":"[2] https:\u002F\u002Fstackoverflow.blog\u002F2023\u002F11\u002F09\u002Fan-intuitive-introduction-to-text-embeddings\u002F","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":4,"end":87,"href":"https:\u002F\u002Fstackoverflow.blog\u002F2023\u002F11\u002F09\u002Fan-intuitive-introduction-to-text-embeddings\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_81":{"__typename":"Paragraph","id":"0164f3af9593_81","name":"c8c7","type":"P","href":null,"layout":null,"metadata":null,"text":"[3] https:\u002F\u002Fvectordatabase.substack.com\u002Fp\u002Fvector-embeddings-101-the-new-building","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":4,"end":80,"href":"https:\u002F\u002Fvectordatabase.substack.com\u002Fp\u002Fvector-embeddings-101-the-new-building","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_82":{"__typename":"Paragraph","id":"0164f3af9593_82","name":"c988","type":"P","href":null,"layout":null,"metadata":null,"text":"[4] https:\u002F\u002Fwww.pinecone.io\u002Flearn\u002Fvector-embeddings-for-developers\u002F","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":4,"end":67,"href":"https:\u002F\u002Fwww.pinecone.io\u002Flearn\u002Fvector-embeddings-for-developers\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_83":{"__typename":"Paragraph","id":"0164f3af9593_83","name":"1aaa","type":"P","href":null,"layout":null,"metadata":null,"text":"[5] https:\u002F\u002Fa16z.com\u002Femerging-architectures-for-llm-applications\u002F","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":4,"end":65,"href":"https:\u002F\u002Fa16z.com\u002Femerging-architectures-for-llm-applications\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_84":{"__typename":"Paragraph","id":"0164f3af9593_84","name":"e1a0","type":"P","href":null,"layout":null,"metadata":null,"text":"[6] https:\u002F\u002Fdatasciencedojo.com\u002Fblog\u002Fvector-embeddings-generative-ai\u002F","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":4,"end":69,"href":"https:\u002F\u002Fdatasciencedojo.com\u002Fblog\u002Fvector-embeddings-generative-ai\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_85":{"__typename":"Paragraph","id":"0164f3af9593_85","name":"eaa3","type":"P","href":null,"layout":null,"metadata":null,"text":"[7] https:\u002F\u002Fcausewriter.ai\u002Fcourses\u002Fai-explainers\u002Flessons\u002Fvector-embedding\u002F","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":4,"end":74,"href":"https:\u002F\u002Fcausewriter.ai\u002Fcourses\u002Fai-explainers\u002Flessons\u002Fvector-embedding\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_86":{"__typename":"Paragraph","id":"0164f3af9593_86","name":"f2b2","type":"P","href":null,"layout":null,"metadata":null,"text":"[8] https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCosine_similarity","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":4,"end":51,"href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FCosine_similarity","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_87":{"__typename":"Paragraph","id":"0164f3af9593_87","name":"2d34","type":"P","href":null,"layout":null,"metadata":null,"text":"[9] https:\u002F\u002Fwww.learndatasci.com\u002Fglossary\u002Fcosine-similarity\u002F","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":4,"end":60,"href":"https:\u002F\u002Fwww.learndatasci.com\u002Fglossary\u002Fcosine-similarity\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_88":{"__typename":"Paragraph","id":"0164f3af9593_88","name":"86cf","type":"P","href":null,"layout":null,"metadata":null,"text":"[10] https:\u002F\u002Fdocs.pinecone.io\u002Fpage\u002Fexamples","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":5,"end":43,"href":"https:\u002F\u002Fdocs.pinecone.io\u002Fpage\u002Fexamples","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_89":{"__typename":"Paragraph","id":"0164f3af9593_89","name":"8248","type":"P","href":null,"layout":null,"metadata":null,"text":"[11] https:\u002F\u002Frealpython.com\u002Fchromadb-vector-database\u002F","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":5,"end":53,"href":"https:\u002F\u002Frealpython.com\u002Fchromadb-vector-database\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_90":{"__typename":"Paragraph","id":"0164f3af9593_90","name":"4316","type":"P","href":null,"layout":null,"metadata":null,"text":"[12] https:\u002F\u002Fcausewriter.ai\u002Fcourses\u002Fai-explainers\u002Flessons\u002Fvector-embedding\u002F","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":5,"end":75,"href":"https:\u002F\u002Fcausewriter.ai\u002Fcourses\u002Fai-explainers\u002Flessons\u002Fvector-embedding\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_91":{"__typename":"Paragraph","id":"0164f3af9593_91","name":"c704","type":"P","href":null,"layout":null,"metadata":null,"text":"[13] https:\u002F\u002Fvectordatabase.substack.com\u002Fp\u002Fvector-embeddings-101-the-new-building","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":5,"end":81,"href":"https:\u002F\u002Fvectordatabase.substack.com\u002Fp\u002Fvector-embeddings-101-the-new-building","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_92":{"__typename":"Paragraph","id":"0164f3af9593_92","name":"9236","type":"P","href":null,"layout":null,"metadata":null,"text":"[14] https:\u002F\u002Fopenai.com\u002Fresearch\u002Fclip","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":5,"end":37,"href":"https:\u002F\u002Fopenai.com\u002Fresearch\u002Fclip","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:0164f3af9593_93":{"__typename":"Paragraph","id":"0164f3af9593_93","name":"f55d","type":"P","href":null,"layout":null,"metadata":null,"text":"[15] https:\u002F\u002Ftowardsdatascience.com\u002Fclip-model-and-the-importance-of-multimodal-embeddings-1c8f6b13bf72","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":5,"end":103,"href":"https:\u002F\u002Ftowardsdatascience.com\u002Fclip-model-and-the-importance-of-multimodal-embeddings-1c8f6b13bf72","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:3fe99b2acc4-viewerId:lo_d46a31de4e77":{"__typename":"CollectionViewerEdge","id":"collectionId:3fe99b2acc4-viewerId:lo_d46a31de4e77","isEditor":false,"isMuting":false},"ImageMetadata:":{"__typename":"ImageMetadata","id":"","originalWidth":0,"originalHeight":0},"PostViewerEdge:postId:ffde295c3558-viewerId:lo_d46a31de4e77":{"__typename":"PostViewerEdge","shouldIndexPostForExternalSearch":true,"id":"postId:ffde295c3558-viewerId:lo_d46a31de4e77"},"Tag:vector-embeddigns":{"__typename":"Tag","id":"vector-embeddigns","displayTitle":"Vector Embeddigns","normalizedTagSlug":"vector-embeddigns"},"Tag:vector-databases":{"__typename":"Tag","id":"vector-databases","displayTitle":"Vector Databases","normalizedTagSlug":"vector-database"},"Tag:generative-ai":{"__typename":"Tag","id":"generative-ai","displayTitle":"Generative Ai","normalizedTagSlug":"generative-ai"},"Tag:llms":{"__typename":"Tag","id":"llms","displayTitle":"Llms","normalizedTagSlug":"llm"},"Tag:semantic-searches":{"__typename":"Tag","id":"semantic-searches","displayTitle":"Semantic Searches","normalizedTagSlug":"semantic-search"},"Membership:bc60a724-4f2e-4a07-bc06-883a0f1c013e":{"__typename":"Membership","tier":"MEMBER","id":"bc60a724-4f2e-4a07-bc06-883a0f1c013e"},"Post:ffde295c3558":{"__typename":"Post","id":"ffde295c3558","collection":{"__ref":"Collection:3fe99b2acc4"},"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"ef38","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:0164f3af9593_0"},{"__ref":"Paragraph:0164f3af9593_1"},{"__ref":"Paragraph:0164f3af9593_2"},{"__ref":"Paragraph:0164f3af9593_3"},{"__ref":"Paragraph:0164f3af9593_4"},{"__ref":"Paragraph:0164f3af9593_5"},{"__ref":"Paragraph:0164f3af9593_6"},{"__ref":"Paragraph:0164f3af9593_7"},{"__ref":"Paragraph:0164f3af9593_8"},{"__ref":"Paragraph:0164f3af9593_9"},{"__ref":"Paragraph:0164f3af9593_10"},{"__ref":"Paragraph:0164f3af9593_11"},{"__ref":"Paragraph:0164f3af9593_12"},{"__ref":"Paragraph:0164f3af9593_13"},{"__ref":"Paragraph:0164f3af9593_14"},{"__ref":"Paragraph:0164f3af9593_15"},{"__ref":"Paragraph:0164f3af9593_16"},{"__ref":"Paragraph:0164f3af9593_17"},{"__ref":"Paragraph:0164f3af9593_18"},{"__ref":"Paragraph:0164f3af9593_19"},{"__ref":"Paragraph:0164f3af9593_20"},{"__ref":"Paragraph:0164f3af9593_21"},{"__ref":"Paragraph:0164f3af9593_22"},{"__ref":"Paragraph:0164f3af9593_23"},{"__ref":"Paragraph:0164f3af9593_24"},{"__ref":"Paragraph:0164f3af9593_25"},{"__ref":"Paragraph:0164f3af9593_26"},{"__ref":"Paragraph:0164f3af9593_27"},{"__ref":"Paragraph:0164f3af9593_28"},{"__ref":"Paragraph:0164f3af9593_29"},{"__ref":"Paragraph:0164f3af9593_30"},{"__ref":"Paragraph:0164f3af9593_31"},{"__ref":"Paragraph:0164f3af9593_32"},{"__ref":"Paragraph:0164f3af9593_33"},{"__ref":"Paragraph:0164f3af9593_34"},{"__ref":"Paragraph:0164f3af9593_35"},{"__ref":"Paragraph:0164f3af9593_36"},{"__ref":"Paragraph:0164f3af9593_37"},{"__ref":"Paragraph:0164f3af9593_38"},{"__ref":"Paragraph:0164f3af9593_39"},{"__ref":"Paragraph:0164f3af9593_40"},{"__ref":"Paragraph:0164f3af9593_41"},{"__ref":"Paragraph:0164f3af9593_42"},{"__ref":"Paragraph:0164f3af9593_43"},{"__ref":"Paragraph:0164f3af9593_44"},{"__ref":"Paragraph:0164f3af9593_45"},{"__ref":"Paragraph:0164f3af9593_46"},{"__ref":"Paragraph:0164f3af9593_47"},{"__ref":"Paragraph:0164f3af9593_48"},{"__ref":"Paragraph:0164f3af9593_49"},{"__ref":"Paragraph:0164f3af9593_50"},{"__ref":"Paragraph:0164f3af9593_51"},{"__ref":"Paragraph:0164f3af9593_52"},{"__ref":"Paragraph:0164f3af9593_53"},{"__ref":"Paragraph:0164f3af9593_54"},{"__ref":"Paragraph:0164f3af9593_55"},{"__ref":"Paragraph:0164f3af9593_56"},{"__ref":"Paragraph:0164f3af9593_57"},{"__ref":"Paragraph:0164f3af9593_58"},{"__ref":"Paragraph:0164f3af9593_59"},{"__ref":"Paragraph:0164f3af9593_60"},{"__ref":"Paragraph:0164f3af9593_61"},{"__ref":"Paragraph:0164f3af9593_62"},{"__ref":"Paragraph:0164f3af9593_63"},{"__ref":"Paragraph:0164f3af9593_64"},{"__ref":"Paragraph:0164f3af9593_65"},{"__ref":"Paragraph:0164f3af9593_66"},{"__ref":"Paragraph:0164f3af9593_67"},{"__ref":"Paragraph:0164f3af9593_68"},{"__ref":"Paragraph:0164f3af9593_69"},{"__ref":"Paragraph:0164f3af9593_70"},{"__ref":"Paragraph:0164f3af9593_71"},{"__ref":"Paragraph:0164f3af9593_72"},{"__ref":"Paragraph:0164f3af9593_73"},{"__ref":"Paragraph:0164f3af9593_74"},{"__ref":"Paragraph:0164f3af9593_75"},{"__ref":"Paragraph:0164f3af9593_76"},{"__ref":"Paragraph:0164f3af9593_77"},{"__ref":"Paragraph:0164f3af9593_78"},{"__ref":"Paragraph:0164f3af9593_79"},{"__ref":"Paragraph:0164f3af9593_80"},{"__ref":"Paragraph:0164f3af9593_81"},{"__ref":"Paragraph:0164f3af9593_82"},{"__ref":"Paragraph:0164f3af9593_83"},{"__ref":"Paragraph:0164f3af9593_84"},{"__ref":"Paragraph:0164f3af9593_85"},{"__ref":"Paragraph:0164f3af9593_86"},{"__ref":"Paragraph:0164f3af9593_87"},{"__ref":"Paragraph:0164f3af9593_88"},{"__ref":"Paragraph:0164f3af9593_89"},{"__ref":"Paragraph:0164f3af9593_90"},{"__ref":"Paragraph:0164f3af9593_91"},{"__ref":"Paragraph:0164f3af9593_92"},{"__ref":"Paragraph:0164f3af9593_93"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:603ab1741c22"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Fai.gopubby.com\u002Fan-intuitive-101-guide-to-vector-embeddings-ffde295c3558","primaryTopic":null,"topics":[{"__typename":"Topic","slug":"machine-learning"}],"isPublished":true,"latestPublishedVersion":"0164f3af9593","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":0},"clapCount":144,"allowResponses":true,"isLimitedState":false,"title":"An Intuitive 101 Guide to Vector Embeddings","isSeries":false,"sequence":null,"uniqueSlug":"an-intuitive-101-guide-to-vector-embeddings-ffde295c3558","socialTitle":"","socialDek":"","canonicalUrl":"","metaDescription":"","latestPublishedAt":1718214851541,"readingTime":8.954088050314466,"previewContent":{"__typename":"PreviewContent","subtitle":"Vector embeddings matter as fundamental building blocks for Generative AI"},"previewImage":{"__ref":"ImageMetadata:0*VGQaay1U0-9NfA2D"},"isShortform":false,"seoTitle":"","firstPublishedAt":1711136511132,"updatedAt":1718529064437,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","viewerEdge":{"__ref":"PostViewerEdge:postId:ffde295c3558-viewerId:lo_d46a31de4e77"},"isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:vector-embeddigns"},{"__ref":"Tag:vector-databases"},{"__ref":"Tag:generative-ai"},{"__ref":"Tag:llms"},{"__ref":"Tag:semantic-searches"}],"isNewsletter":false,"statusForCollection":"APPROVED","pendingCollection":null,"detectedLanguage":"en","wordCount":2152,"layerCake":6}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"HIT"}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.ccf5d1ad.js"></script><script src="https://cdn-client.medium.com/lite/static/js/9865.1496d74a.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.3c1d68ac.js"></script><script src="https://cdn-client.medium.com/lite/static/js/instrumentation.d9108df7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.ff22a7a5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9120.5df29668.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5049.d1ead72d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4810.6318add7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6618.db187378.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1386.014e2ad3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9977.343f5002.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5250.fc15c18c.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8261.80c0631e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7975.b019beb1.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2648.a582e725.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2712.0f6c85f5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2793.01d2b056.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1530.2779d8ee.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3735.ca2f95e3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5642.0ebb50fd.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6546.ef575ba6.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6834.f2d3924e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2420.0330d157.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2106.21ff89d3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6696.92b2dfc3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5832.a567559e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3366.1571a1d5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6040.6ceb7f43.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4391.fd55a702.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.3c324843.chunk.js"></script><script>window.main();</script></body></html>